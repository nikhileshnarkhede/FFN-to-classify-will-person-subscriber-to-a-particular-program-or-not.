{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pcJROarEqi0d",
        "nnaMCCt_2-Wb",
        "w0ij8FtZrYwi",
        "K8BAz4PWv1o_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpd7y87bbSsj",
        "outputId": "25d9c6b8-0708-4739-8c43-032b5fb9960e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "data=pd.read_csv(\"/content/gdrive/My Drive/Subscribers.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "95RYQpV7bx7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = data\n"
      ],
      "metadata": {
        "id": "eitrOpYfboG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "VjEGrk_4c8V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "VcQt_N56ebjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mydata.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "0fyA-SjbeggG",
        "outputId": "36b9ca59-966c-4e8c-bc11-36d7616c0f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         V1           V2          V3         V4          V5           V6  \\\n",
              "0 -0.211875    743952.92   743952.92   200000.0   743952.92   200000.000   \n",
              "1  0.241488  11295310.87  8034290.99    32000.0  8034290.99    18000.000   \n",
              "2  0.459032     20363.68   317922.94  1650000.0   317922.94  1650000.000   \n",
              "3  0.000000    856120.91   856120.91        0.0   856120.91    45554.885   \n",
              "4  8.270783    194485.64   412330.33   835000.0   412330.33   835000.000   \n",
              "\n",
              "          V7         V8          V9         V10  ...           V42       V43  \\\n",
              "0   200000.0  -0.069396   943952.92        0.00  ...  1.034232e+06   1966.57   \n",
              "1    14000.0   0.167411  7508345.76  1160925.13  ...  5.665658e+07  49957.65   \n",
              "2  1650000.0  46.068404  1655168.31        0.00  ...  2.654720e+04    453.96   \n",
              "3        0.0   0.000000   856120.91        0.00  ...  8.506973e+05   2045.09   \n",
              "4   835000.0  -0.272225     2241.64    78625.00  ...  5.572559e+04     70.01   \n",
              "\n",
              "        V44       V45       V46    V47           V48   V49       V50  \\\n",
              "0   1990.82   1752.89  100000.0  147.0   1826.046667  28.0   2557.22   \n",
              "1  11104.54  17711.99   38000.0   19.0  26467.683330  19.0  12807.07   \n",
              "2      9.64     58.83   45072.0    0.0    315.506667   0.0     32.12   \n",
              "3   2045.09   2011.19   45072.0   30.0   2045.090000  19.0   2029.79   \n",
              "4    100.60     89.59   31080.0    0.0    294.580000   0.0     26.95   \n",
              "\n",
              "   Subscribers  \n",
              "0            0  \n",
              "1            0  \n",
              "2            1  \n",
              "3            0  \n",
              "4            0  \n",
              "\n",
              "[5 rows x 51 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccb325ba-190f-4a57-aaa4-66322f731faa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "      <th>Subscribers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.211875</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>200000.000</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>-0.069396</td>\n",
              "      <td>943952.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1.034232e+06</td>\n",
              "      <td>1966.57</td>\n",
              "      <td>1990.82</td>\n",
              "      <td>1752.89</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>1826.046667</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2557.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.241488</td>\n",
              "      <td>11295310.87</td>\n",
              "      <td>8034290.99</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>8034290.99</td>\n",
              "      <td>18000.000</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>0.167411</td>\n",
              "      <td>7508345.76</td>\n",
              "      <td>1160925.13</td>\n",
              "      <td>...</td>\n",
              "      <td>5.665658e+07</td>\n",
              "      <td>49957.65</td>\n",
              "      <td>11104.54</td>\n",
              "      <td>17711.99</td>\n",
              "      <td>38000.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26467.683330</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12807.07</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.459032</td>\n",
              "      <td>20363.68</td>\n",
              "      <td>317922.94</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>317922.94</td>\n",
              "      <td>1650000.000</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>46.068404</td>\n",
              "      <td>1655168.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>2.654720e+04</td>\n",
              "      <td>453.96</td>\n",
              "      <td>9.64</td>\n",
              "      <td>58.83</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>315.506667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.12</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>8.506973e+05</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>2011.19</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2045.090000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2029.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.270783</td>\n",
              "      <td>194485.64</td>\n",
              "      <td>412330.33</td>\n",
              "      <td>835000.0</td>\n",
              "      <td>412330.33</td>\n",
              "      <td>835000.000</td>\n",
              "      <td>835000.0</td>\n",
              "      <td>-0.272225</td>\n",
              "      <td>2241.64</td>\n",
              "      <td>78625.00</td>\n",
              "      <td>...</td>\n",
              "      <td>5.572559e+04</td>\n",
              "      <td>70.01</td>\n",
              "      <td>100.60</td>\n",
              "      <td>89.59</td>\n",
              "      <td>31080.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>294.580000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccb325ba-190f-4a57-aaa4-66322f731faa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ccb325ba-190f-4a57-aaa4-66322f731faa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ccb325ba-190f-4a57-aaa4-66322f731faa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1b497b84-c2ae-462e-b8ee-a5186736289c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b497b84-c2ae-462e-b8ee-a5186736289c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1b497b84-c2ae-462e-b8ee-a5186736289c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mydata"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Kgo5LzNfWxZ",
        "outputId": "b2f5d555-a0b4-4809-95bc-56e43097b27b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300000, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = mydata.drop(columns=['Subscribers'],axis=1)\n",
        "y = mydata['Subscribers']"
      ],
      "metadata": {
        "id": "wmquuGb-fbXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "U239z8TLfy17",
        "outputId": "97dc00be-747b-46d7-e7c2-02f8bdddf16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              V1           V2          V3         V4          V5           V6  \\\n",
              "0      -0.211875    743952.92   743952.92   200000.0   743952.92   200000.000   \n",
              "1       0.241488  11295310.87  8034290.99    32000.0  8034290.99    18000.000   \n",
              "2       0.459032     20363.68   317922.94  1650000.0   317922.94  1650000.000   \n",
              "3       0.000000    856120.91   856120.91        0.0   856120.91    45554.885   \n",
              "4       8.270783    194485.64   412330.33   835000.0   412330.33   835000.000   \n",
              "...          ...          ...         ...        ...         ...          ...   \n",
              "299995 -0.335141     88883.08    93589.63    13500.0    93589.63    13500.000   \n",
              "299996 -0.685300    188409.84   150858.12        0.0   150858.12    45554.885   \n",
              "299997 -0.011814     80169.18    81134.70        0.0    81134.70    45554.885   \n",
              "299998  0.000000    356125.94   356125.94        0.0   356125.94    45554.885   \n",
              "299999  0.346458    216437.23   239995.33    40728.0   239995.33    30826.000   \n",
              "\n",
              "               V7         V8          V9         V10  ...  V41           V42  \\\n",
              "0        200000.0  -0.069396   943952.92        0.00  ...    1  1.034232e+06   \n",
              "1         14000.0   0.167411  7508345.76  1160925.13  ...    2  5.665658e+07   \n",
              "2       1650000.0  46.068404  1655168.31        0.00  ...    4  2.654720e+04   \n",
              "3             0.0   0.000000   856120.91        0.00  ...    0  8.506973e+05   \n",
              "4        835000.0  -0.272225     2241.64    78625.00  ...    5  5.572559e+04   \n",
              "...           ...        ...         ...         ...  ...  ...           ...   \n",
              "299995        0.0  -0.319523   100968.08    66000.00  ...    0  2.525699e+07   \n",
              "299996        0.0   0.251368    89409.84   618700.00  ...    0  3.840856e+05   \n",
              "299997        0.0  -0.565757    81169.18        0.00  ...    0  8.067076e+04   \n",
              "299998        0.0   0.000000   356125.94        0.00  ...    0  3.547008e+05   \n",
              "299999    40728.0   1.480294   150665.23    55214.00  ...    4  2.592562e+05   \n",
              "\n",
              "             V43       V44       V45       V46    V47           V48    V49  \\\n",
              "0        1966.57   1990.82   1752.89  100000.0  147.0   1826.046667   28.0   \n",
              "1       49957.65  11104.54  17711.99   38000.0   19.0  26467.683330   19.0   \n",
              "2         453.96      9.64     58.83   45072.0    0.0    315.506667    0.0   \n",
              "3        2045.09   2045.09   2011.19   45072.0   30.0   2045.090000   19.0   \n",
              "4          70.01    100.60     89.59   31080.0    0.0    294.580000    0.0   \n",
              "...          ...       ...       ...       ...    ...           ...    ...   \n",
              "299995    442.29    580.88    730.08   95000.0  327.0    455.573333  217.0   \n",
              "299996    899.20    792.45    530.60  400000.0   17.0    660.233333   17.0   \n",
              "299997   8255.58   8515.33   8416.55  290434.0   87.0   8325.626667   61.0   \n",
              "299998    741.93    741.93    733.02   45072.0  240.0    741.930000  240.0   \n",
              "299999   8000.44   9597.78  16392.77  113652.0   27.0   8291.416667    4.0   \n",
              "\n",
              "             V50  \n",
              "0        2557.22  \n",
              "1       12807.07  \n",
              "2          32.12  \n",
              "3        2029.79  \n",
              "4          26.95  \n",
              "...          ...  \n",
              "299995    840.18  \n",
              "299996    612.61  \n",
              "299997   8380.94  \n",
              "299998    741.93  \n",
              "299999  16744.22  \n",
              "\n",
              "[300000 rows x 50 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd093f70-e454-45d8-ae73-7aa73bb0ec4c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V41</th>\n",
              "      <th>V42</th>\n",
              "      <th>V43</th>\n",
              "      <th>V44</th>\n",
              "      <th>V45</th>\n",
              "      <th>V46</th>\n",
              "      <th>V47</th>\n",
              "      <th>V48</th>\n",
              "      <th>V49</th>\n",
              "      <th>V50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.211875</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>743952.92</td>\n",
              "      <td>200000.000</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>-0.069396</td>\n",
              "      <td>943952.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.034232e+06</td>\n",
              "      <td>1966.57</td>\n",
              "      <td>1990.82</td>\n",
              "      <td>1752.89</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>1826.046667</td>\n",
              "      <td>28.0</td>\n",
              "      <td>2557.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.241488</td>\n",
              "      <td>11295310.87</td>\n",
              "      <td>8034290.99</td>\n",
              "      <td>32000.0</td>\n",
              "      <td>8034290.99</td>\n",
              "      <td>18000.000</td>\n",
              "      <td>14000.0</td>\n",
              "      <td>0.167411</td>\n",
              "      <td>7508345.76</td>\n",
              "      <td>1160925.13</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>5.665658e+07</td>\n",
              "      <td>49957.65</td>\n",
              "      <td>11104.54</td>\n",
              "      <td>17711.99</td>\n",
              "      <td>38000.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>26467.683330</td>\n",
              "      <td>19.0</td>\n",
              "      <td>12807.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.459032</td>\n",
              "      <td>20363.68</td>\n",
              "      <td>317922.94</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>317922.94</td>\n",
              "      <td>1650000.000</td>\n",
              "      <td>1650000.0</td>\n",
              "      <td>46.068404</td>\n",
              "      <td>1655168.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2.654720e+04</td>\n",
              "      <td>453.96</td>\n",
              "      <td>9.64</td>\n",
              "      <td>58.83</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>315.506667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.0</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>856120.91</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8.506973e+05</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>2045.09</td>\n",
              "      <td>2011.19</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>2045.090000</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2029.79</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8.270783</td>\n",
              "      <td>194485.64</td>\n",
              "      <td>412330.33</td>\n",
              "      <td>835000.0</td>\n",
              "      <td>412330.33</td>\n",
              "      <td>835000.000</td>\n",
              "      <td>835000.0</td>\n",
              "      <td>-0.272225</td>\n",
              "      <td>2241.64</td>\n",
              "      <td>78625.00</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5.572559e+04</td>\n",
              "      <td>70.01</td>\n",
              "      <td>100.60</td>\n",
              "      <td>89.59</td>\n",
              "      <td>31080.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>294.580000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299995</th>\n",
              "      <td>-0.335141</td>\n",
              "      <td>88883.08</td>\n",
              "      <td>93589.63</td>\n",
              "      <td>13500.0</td>\n",
              "      <td>93589.63</td>\n",
              "      <td>13500.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.319523</td>\n",
              "      <td>100968.08</td>\n",
              "      <td>66000.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>2.525699e+07</td>\n",
              "      <td>442.29</td>\n",
              "      <td>580.88</td>\n",
              "      <td>730.08</td>\n",
              "      <td>95000.0</td>\n",
              "      <td>327.0</td>\n",
              "      <td>455.573333</td>\n",
              "      <td>217.0</td>\n",
              "      <td>840.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299996</th>\n",
              "      <td>-0.685300</td>\n",
              "      <td>188409.84</td>\n",
              "      <td>150858.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>150858.12</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.251368</td>\n",
              "      <td>89409.84</td>\n",
              "      <td>618700.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3.840856e+05</td>\n",
              "      <td>899.20</td>\n",
              "      <td>792.45</td>\n",
              "      <td>530.60</td>\n",
              "      <td>400000.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>660.233333</td>\n",
              "      <td>17.0</td>\n",
              "      <td>612.61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299997</th>\n",
              "      <td>-0.011814</td>\n",
              "      <td>80169.18</td>\n",
              "      <td>81134.70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81134.70</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.565757</td>\n",
              "      <td>81169.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>8.067076e+04</td>\n",
              "      <td>8255.58</td>\n",
              "      <td>8515.33</td>\n",
              "      <td>8416.55</td>\n",
              "      <td>290434.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>8325.626667</td>\n",
              "      <td>61.0</td>\n",
              "      <td>8380.94</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299998</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>356125.94</td>\n",
              "      <td>356125.94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>356125.94</td>\n",
              "      <td>45554.885</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>356125.94</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3.547008e+05</td>\n",
              "      <td>741.93</td>\n",
              "      <td>741.93</td>\n",
              "      <td>733.02</td>\n",
              "      <td>45072.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>741.930000</td>\n",
              "      <td>240.0</td>\n",
              "      <td>741.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299999</th>\n",
              "      <td>0.346458</td>\n",
              "      <td>216437.23</td>\n",
              "      <td>239995.33</td>\n",
              "      <td>40728.0</td>\n",
              "      <td>239995.33</td>\n",
              "      <td>30826.000</td>\n",
              "      <td>40728.0</td>\n",
              "      <td>1.480294</td>\n",
              "      <td>150665.23</td>\n",
              "      <td>55214.00</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>2.592562e+05</td>\n",
              "      <td>8000.44</td>\n",
              "      <td>9597.78</td>\n",
              "      <td>16392.77</td>\n",
              "      <td>113652.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>8291.416667</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16744.22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300000 rows × 50 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd093f70-e454-45d8-ae73-7aa73bb0ec4c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd093f70-e454-45d8-ae73-7aa73bb0ec4c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd093f70-e454-45d8-ae73-7aa73bb0ec4c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3daae077-45ab-4f82-8201-0eeb0f557d6d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3daae077-45ab-4f82-8201-0eeb0f557d6d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3daae077-45ab-4f82-8201-0eeb0f557d6d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f89e8ca7-626e-4d90-a130-59909695a3f3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('x')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f89e8ca7-626e-4d90-a130-59909695a3f3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('x');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xY7jgBpfzgb",
        "outputId": "83e3b0d3-63e9-4a1b-b716-3b812fd963c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0\n",
              "1         0\n",
              "2         1\n",
              "3         0\n",
              "4         0\n",
              "         ..\n",
              "299995    0\n",
              "299996    0\n",
              "299997    0\n",
              "299998    0\n",
              "299999    1\n",
              "Name: Subscribers, Length: 300000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_val,y_train,y_val = train_test_split(x,y,test_size = 0.2,random_state=2)"
      ],
      "metadata": {
        "id": "uegEXkIif_Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler().fit(x_train)"
      ],
      "metadata": {
        "id": "EefouVLagXcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sd_x_train = scaler.transform(x_train)\n",
        "sd_x_test = scaler.transform(x_val)"
      ],
      "metadata": {
        "id": "OjyPFb5bglKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTLSr5E-g72U",
        "outputId": "a52d7c67-0f59-4ca4-a038-e7f6e2e1eaa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    198601\n",
              "1     41399\n",
              "Name: Subscribers, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cw = class_weight.compute_class_weight(class_weight='balanced',classes = np.unique(y_train),y = y_train)"
      ],
      "metadata": {
        "id": "0XsZFnJGhf_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHWWej86iTKn",
        "outputId": "a4bd7d46-ab53-4e5b-ef1a-8266576cd338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60422656, 2.89862074])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cw_dict =dict(enumerate(cw))"
      ],
      "metadata": {
        "id": "9_b25LS4iVZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cw_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORZJFzGBiejw",
        "outputId": "ad4acb3f-8d6b-46d4-e9a0-5b9cc8a3fdbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 0.6042265648209224, 1: 2.898620739631392}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sequential API"
      ],
      "metadata": {
        "id": "pcJROarEqi0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.regularizers import L1,L2"
      ],
      "metadata": {
        "id": "HCfsO-18qa0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq = Sequential()\n",
        "\n",
        "model_seq.add(Dense(30,input_dim = 50,activation = 'relu',kernel_regularizer = L1(0.01),name = 'h1'))\n",
        "model_seq.add(BatchNormalization(name = 'bn_h1'))\n",
        "model_seq.add(Dropout(0.2,name = 'dr_h1'))\n",
        "\n",
        "model_seq.add(Dense(20,input_dim = 30,activation = 'relu',kernel_regularizer = L1(0.01),name = 'h2'))\n",
        "model_seq.add(BatchNormalization(name = 'bn_h2'))\n",
        "model_seq.add(Dropout(0.2,name = 'dr_h2'))\n",
        "\n",
        "model_seq.add(Dense(10,input_dim = 20,activation = 'relu',kernel_regularizer = L1(0.01),name = 'h3'))\n",
        "model_seq.add(BatchNormalization(name = 'bn_h3'))\n",
        "model_seq.add(Dropout(0.2,name = 'dr_h3'))\n",
        "\n",
        "model_seq.add(Dense(1,input_dim = 10,activation = 'sigmoid',name = 'output'))\n"
      ],
      "metadata": {
        "id": "LVmDGWJgrXi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model"
      ],
      "metadata": {
        "id": "9MBWKMZLt1CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_model(model = model_seq,show_shapes = True)"
      ],
      "metadata": {
        "id": "E97BvBjswC9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics =['acc'])\n"
      ],
      "metadata": {
        "id": "GB-hkTTgxIL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQhAZXPlybxR",
        "outputId": "c803b108-4ab8-4d9e-ee9b-83e7c48bbea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " h1 (Dense)                  (None, 30)                1530      \n",
            "                                                                 \n",
            " bn_h1 (BatchNormalization)  (None, 30)                120       \n",
            "                                                                 \n",
            " dr_h1 (Dropout)             (None, 30)                0         \n",
            "                                                                 \n",
            " h2 (Dense)                  (None, 20)                620       \n",
            "                                                                 \n",
            " bn_h2 (BatchNormalization)  (None, 20)                80        \n",
            "                                                                 \n",
            " dr_h2 (Dropout)             (None, 20)                0         \n",
            "                                                                 \n",
            " h3 (Dense)                  (None, 10)                210       \n",
            "                                                                 \n",
            " bn_h3 (BatchNormalization)  (None, 10)                40        \n",
            "                                                                 \n",
            " dr_h3 (Dropout)             (None, 10)                0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2611 (10.20 KB)\n",
            "Trainable params: 2491 (9.73 KB)\n",
            "Non-trainable params: 120 (480.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_seq.fit(sd_x_train,y_train,validation_data = (sd_x_test,y_val),class_weight = cw_dict,\n",
        "              epochs = 1000,batch_size = 1000,verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCLWdzwIyr85",
        "outputId": "29cb5b07-fb98-4080-b769-e6382432c37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5515 - acc: 0.8102 - val_loss: 0.4619 - val_acc: 0.8598\n",
            "Epoch 2/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8101 - val_loss: 0.5059 - val_acc: 0.8291\n",
            "Epoch 3/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5502 - acc: 0.8089 - val_loss: 0.5080 - val_acc: 0.8422\n",
            "Epoch 4/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8103 - val_loss: 0.4967 - val_acc: 0.8347\n",
            "Epoch 5/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5512 - acc: 0.8104 - val_loss: 0.5701 - val_acc: 0.7876\n",
            "Epoch 6/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5491 - acc: 0.8109 - val_loss: 0.5362 - val_acc: 0.8174\n",
            "Epoch 7/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5514 - acc: 0.8091 - val_loss: 0.4707 - val_acc: 0.8618\n",
            "Epoch 8/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8099 - val_loss: 0.5399 - val_acc: 0.8109\n",
            "Epoch 9/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8096 - val_loss: 0.5937 - val_acc: 0.7774\n",
            "Epoch 10/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8108 - val_loss: 0.5734 - val_acc: 0.8020\n",
            "Epoch 11/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5521 - acc: 0.8070 - val_loss: 0.4419 - val_acc: 0.8626\n",
            "Epoch 12/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5512 - acc: 0.8103 - val_loss: 0.4357 - val_acc: 0.8571\n",
            "Epoch 13/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5502 - acc: 0.8108 - val_loss: 0.5046 - val_acc: 0.8449\n",
            "Epoch 14/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8091 - val_loss: 0.5189 - val_acc: 0.8327\n",
            "Epoch 15/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5494 - acc: 0.8107 - val_loss: 0.4907 - val_acc: 0.8490\n",
            "Epoch 16/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5530 - acc: 0.8073 - val_loss: 0.6138 - val_acc: 0.7622\n",
            "Epoch 17/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5488 - acc: 0.8093 - val_loss: 0.5276 - val_acc: 0.8206\n",
            "Epoch 18/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5507 - acc: 0.8101 - val_loss: 0.4874 - val_acc: 0.8602\n",
            "Epoch 19/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5509 - acc: 0.8115 - val_loss: 0.6404 - val_acc: 0.7304\n",
            "Epoch 20/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5498 - acc: 0.8087 - val_loss: 0.4856 - val_acc: 0.8555\n",
            "Epoch 21/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5521 - acc: 0.8064 - val_loss: 0.5195 - val_acc: 0.8357\n",
            "Epoch 22/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5505 - acc: 0.8104 - val_loss: 0.4958 - val_acc: 0.8483\n",
            "Epoch 23/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8094 - val_loss: 0.4445 - val_acc: 0.8595\n",
            "Epoch 24/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8103 - val_loss: 0.5784 - val_acc: 0.7989\n",
            "Epoch 25/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5517 - acc: 0.8095 - val_loss: 0.5088 - val_acc: 0.8382\n",
            "Epoch 26/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5482 - acc: 0.8110 - val_loss: 0.5975 - val_acc: 0.8007\n",
            "Epoch 27/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8091 - val_loss: 0.5105 - val_acc: 0.8454\n",
            "Epoch 28/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5528 - acc: 0.8103 - val_loss: 0.5073 - val_acc: 0.8433\n",
            "Epoch 29/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5513 - acc: 0.8121 - val_loss: 0.5326 - val_acc: 0.8260\n",
            "Epoch 30/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8110 - val_loss: 0.4987 - val_acc: 0.8573\n",
            "Epoch 31/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8110 - val_loss: 0.4702 - val_acc: 0.8456\n",
            "Epoch 32/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8092 - val_loss: 0.4867 - val_acc: 0.8494\n",
            "Epoch 33/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5478 - acc: 0.8132 - val_loss: 0.5573 - val_acc: 0.8189\n",
            "Epoch 34/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5493 - acc: 0.8090 - val_loss: 0.5540 - val_acc: 0.8278\n",
            "Epoch 35/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8096 - val_loss: 0.5221 - val_acc: 0.8249\n",
            "Epoch 36/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5503 - acc: 0.8114 - val_loss: 0.5310 - val_acc: 0.8318\n",
            "Epoch 37/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5507 - acc: 0.8105 - val_loss: 0.5226 - val_acc: 0.8267\n",
            "Epoch 38/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8091 - val_loss: 0.4783 - val_acc: 0.8540\n",
            "Epoch 39/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5496 - acc: 0.8109 - val_loss: 0.5540 - val_acc: 0.7959\n",
            "Epoch 40/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5531 - acc: 0.8060 - val_loss: 0.5235 - val_acc: 0.8141\n",
            "Epoch 41/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8078 - val_loss: 0.5272 - val_acc: 0.8266\n",
            "Epoch 42/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8083 - val_loss: 0.5352 - val_acc: 0.8275\n",
            "Epoch 43/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8110 - val_loss: 0.5399 - val_acc: 0.8188\n",
            "Epoch 44/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8096 - val_loss: 0.7380 - val_acc: 0.6212\n",
            "Epoch 45/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5508 - acc: 0.8106 - val_loss: 0.5789 - val_acc: 0.8134\n",
            "Epoch 46/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5544 - acc: 0.8103 - val_loss: 0.5035 - val_acc: 0.8315\n",
            "Epoch 47/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5509 - acc: 0.8098 - val_loss: 0.5459 - val_acc: 0.8249\n",
            "Epoch 48/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8109 - val_loss: 0.4909 - val_acc: 0.8548\n",
            "Epoch 49/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5518 - acc: 0.8105 - val_loss: 0.5563 - val_acc: 0.8004\n",
            "Epoch 50/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5552 - acc: 0.8081 - val_loss: 0.5291 - val_acc: 0.8365\n",
            "Epoch 51/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5478 - acc: 0.8109 - val_loss: 0.5963 - val_acc: 0.8053\n",
            "Epoch 52/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5531 - acc: 0.8079 - val_loss: 0.4745 - val_acc: 0.8536\n",
            "Epoch 53/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8074 - val_loss: 0.5343 - val_acc: 0.8330\n",
            "Epoch 54/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5501 - acc: 0.8109 - val_loss: 0.5589 - val_acc: 0.7993\n",
            "Epoch 55/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5506 - acc: 0.8085 - val_loss: 0.5070 - val_acc: 0.8373\n",
            "Epoch 56/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5502 - acc: 0.8096 - val_loss: 0.5715 - val_acc: 0.7921\n",
            "Epoch 57/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5487 - acc: 0.8090 - val_loss: 0.5597 - val_acc: 0.8217\n",
            "Epoch 58/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5507 - acc: 0.8092 - val_loss: 0.4875 - val_acc: 0.8435\n",
            "Epoch 59/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5521 - acc: 0.8079 - val_loss: 0.5207 - val_acc: 0.8246\n",
            "Epoch 60/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8101 - val_loss: 0.5933 - val_acc: 0.7967\n",
            "Epoch 61/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5479 - acc: 0.8120 - val_loss: 0.6174 - val_acc: 0.7479\n",
            "Epoch 62/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5502 - acc: 0.8102 - val_loss: 0.6164 - val_acc: 0.7824\n",
            "Epoch 63/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5488 - acc: 0.8124 - val_loss: 0.5413 - val_acc: 0.8217\n",
            "Epoch 64/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5476 - acc: 0.8109 - val_loss: 0.6407 - val_acc: 0.7389\n",
            "Epoch 65/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5517 - acc: 0.8103 - val_loss: 0.6077 - val_acc: 0.7466\n",
            "Epoch 66/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8069 - val_loss: 0.4673 - val_acc: 0.8480\n",
            "Epoch 67/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8109 - val_loss: 0.5264 - val_acc: 0.8291\n",
            "Epoch 68/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5528 - acc: 0.8107 - val_loss: 0.5155 - val_acc: 0.8129\n",
            "Epoch 69/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5482 - acc: 0.8122 - val_loss: 0.7396 - val_acc: 0.6350\n",
            "Epoch 70/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5527 - acc: 0.8075 - val_loss: 0.4962 - val_acc: 0.8516\n",
            "Epoch 71/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5487 - acc: 0.8100 - val_loss: 0.5381 - val_acc: 0.8229\n",
            "Epoch 72/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5493 - acc: 0.8109 - val_loss: 0.5741 - val_acc: 0.8040\n",
            "Epoch 73/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5506 - acc: 0.8091 - val_loss: 0.5591 - val_acc: 0.7930\n",
            "Epoch 74/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5470 - acc: 0.8121 - val_loss: 0.5604 - val_acc: 0.8427\n",
            "Epoch 75/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8113 - val_loss: 0.6671 - val_acc: 0.7286\n",
            "Epoch 76/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8102 - val_loss: 0.4811 - val_acc: 0.8478\n",
            "Epoch 77/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5514 - acc: 0.8088 - val_loss: 0.5099 - val_acc: 0.8401\n",
            "Epoch 78/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8082 - val_loss: 0.5047 - val_acc: 0.8379\n",
            "Epoch 79/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5514 - acc: 0.8098 - val_loss: 0.5040 - val_acc: 0.8338\n",
            "Epoch 80/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5504 - acc: 0.8091 - val_loss: 0.4938 - val_acc: 0.8474\n",
            "Epoch 81/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5499 - acc: 0.8120 - val_loss: 0.5058 - val_acc: 0.8489\n",
            "Epoch 82/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5492 - acc: 0.8115 - val_loss: 0.6012 - val_acc: 0.7641\n",
            "Epoch 83/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8112 - val_loss: 0.5479 - val_acc: 0.8245\n",
            "Epoch 84/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8094 - val_loss: 0.5322 - val_acc: 0.8204\n",
            "Epoch 85/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8111 - val_loss: 0.5868 - val_acc: 0.7902\n",
            "Epoch 86/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8077 - val_loss: 0.5267 - val_acc: 0.8216\n",
            "Epoch 87/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5502 - acc: 0.8102 - val_loss: 0.5505 - val_acc: 0.8095\n",
            "Epoch 88/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5504 - acc: 0.8085 - val_loss: 0.5204 - val_acc: 0.8314\n",
            "Epoch 89/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5503 - acc: 0.8117 - val_loss: 0.5347 - val_acc: 0.8125\n",
            "Epoch 90/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5490 - acc: 0.8100 - val_loss: 0.7318 - val_acc: 0.6608\n",
            "Epoch 91/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8087 - val_loss: 0.5262 - val_acc: 0.8265\n",
            "Epoch 92/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5517 - acc: 0.8090 - val_loss: 0.5037 - val_acc: 0.8466\n",
            "Epoch 93/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5477 - acc: 0.8093 - val_loss: 0.5442 - val_acc: 0.8118\n",
            "Epoch 94/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5514 - acc: 0.8084 - val_loss: 0.5738 - val_acc: 0.8027\n",
            "Epoch 95/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5575 - acc: 0.8019 - val_loss: 0.5111 - val_acc: 0.8486\n",
            "Epoch 96/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8104 - val_loss: 0.5850 - val_acc: 0.7855\n",
            "Epoch 97/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5493 - acc: 0.8103 - val_loss: 0.5683 - val_acc: 0.7812\n",
            "Epoch 98/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5501 - acc: 0.8095 - val_loss: 0.4826 - val_acc: 0.8513\n",
            "Epoch 99/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8103 - val_loss: 0.5023 - val_acc: 0.8494\n",
            "Epoch 100/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5490 - acc: 0.8123 - val_loss: 0.4947 - val_acc: 0.8463\n",
            "Epoch 101/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5482 - acc: 0.8099 - val_loss: 0.5456 - val_acc: 0.8203\n",
            "Epoch 102/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5523 - acc: 0.8073 - val_loss: 0.4924 - val_acc: 0.8423\n",
            "Epoch 103/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5493 - acc: 0.8107 - val_loss: 0.5757 - val_acc: 0.8040\n",
            "Epoch 104/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5497 - acc: 0.8127 - val_loss: 0.5255 - val_acc: 0.8419\n",
            "Epoch 105/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8099 - val_loss: 0.4531 - val_acc: 0.8520\n",
            "Epoch 106/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8055 - val_loss: 0.5229 - val_acc: 0.8364\n",
            "Epoch 107/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5507 - acc: 0.8093 - val_loss: 0.5174 - val_acc: 0.8278\n",
            "Epoch 108/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8102 - val_loss: 0.5008 - val_acc: 0.8502\n",
            "Epoch 109/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5488 - acc: 0.8096 - val_loss: 0.4988 - val_acc: 0.8443\n",
            "Epoch 110/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5483 - acc: 0.8119 - val_loss: 0.4872 - val_acc: 0.8548\n",
            "Epoch 111/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5590 - acc: 0.8106 - val_loss: 0.4484 - val_acc: 0.8612\n",
            "Epoch 112/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5534 - acc: 0.8129 - val_loss: 0.5382 - val_acc: 0.8343\n",
            "Epoch 113/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8117 - val_loss: 0.5209 - val_acc: 0.8389\n",
            "Epoch 114/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8118 - val_loss: 0.6663 - val_acc: 0.7568\n",
            "Epoch 115/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8100 - val_loss: 0.5304 - val_acc: 0.8316\n",
            "Epoch 116/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5503 - acc: 0.8105 - val_loss: 0.5399 - val_acc: 0.8330\n",
            "Epoch 117/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5494 - acc: 0.8095 - val_loss: 0.4912 - val_acc: 0.8508\n",
            "Epoch 118/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5510 - acc: 0.8085 - val_loss: 0.5040 - val_acc: 0.8408\n",
            "Epoch 119/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5512 - acc: 0.8094 - val_loss: 0.5022 - val_acc: 0.8469\n",
            "Epoch 120/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5491 - acc: 0.8104 - val_loss: 0.5091 - val_acc: 0.8375\n",
            "Epoch 121/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5478 - acc: 0.8127 - val_loss: 0.4895 - val_acc: 0.8536\n",
            "Epoch 122/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8084 - val_loss: 0.4993 - val_acc: 0.8416\n",
            "Epoch 123/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8108 - val_loss: 0.5014 - val_acc: 0.8605\n",
            "Epoch 124/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5500 - acc: 0.8097 - val_loss: 0.5776 - val_acc: 0.7682\n",
            "Epoch 125/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5476 - acc: 0.8125 - val_loss: 0.5810 - val_acc: 0.7910\n",
            "Epoch 126/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8118 - val_loss: 0.5341 - val_acc: 0.8305\n",
            "Epoch 127/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5478 - acc: 0.8112 - val_loss: 0.5854 - val_acc: 0.7786\n",
            "Epoch 128/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5519 - acc: 0.8122 - val_loss: 0.6214 - val_acc: 0.7970\n",
            "Epoch 129/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5541 - acc: 0.8077 - val_loss: 0.5544 - val_acc: 0.8037\n",
            "Epoch 130/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5503 - acc: 0.8110 - val_loss: 0.5159 - val_acc: 0.8392\n",
            "Epoch 131/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5478 - acc: 0.8113 - val_loss: 0.4943 - val_acc: 0.8495\n",
            "Epoch 132/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5514 - acc: 0.8076 - val_loss: 0.5287 - val_acc: 0.8363\n",
            "Epoch 133/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5493 - acc: 0.8104 - val_loss: 0.5045 - val_acc: 0.8328\n",
            "Epoch 134/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5484 - acc: 0.8105 - val_loss: 0.5456 - val_acc: 0.8117\n",
            "Epoch 135/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8071 - val_loss: 0.5200 - val_acc: 0.8365\n",
            "Epoch 136/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5492 - acc: 0.8089 - val_loss: 0.5751 - val_acc: 0.8034\n",
            "Epoch 137/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8078 - val_loss: 0.5686 - val_acc: 0.7979\n",
            "Epoch 138/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5509 - acc: 0.8079 - val_loss: 0.5202 - val_acc: 0.8285\n",
            "Epoch 139/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5496 - acc: 0.8079 - val_loss: 0.6015 - val_acc: 0.7458\n",
            "Epoch 140/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5486 - acc: 0.8091 - val_loss: 0.5042 - val_acc: 0.8514\n",
            "Epoch 141/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5490 - acc: 0.8115 - val_loss: 0.5350 - val_acc: 0.8199\n",
            "Epoch 142/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5495 - acc: 0.8069 - val_loss: 0.5820 - val_acc: 0.8050\n",
            "Epoch 143/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8081 - val_loss: 0.4955 - val_acc: 0.8417\n",
            "Epoch 144/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8089 - val_loss: 0.5700 - val_acc: 0.7936\n",
            "Epoch 145/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5478 - acc: 0.8119 - val_loss: 0.5073 - val_acc: 0.8415\n",
            "Epoch 146/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5498 - acc: 0.8100 - val_loss: 0.5419 - val_acc: 0.8279\n",
            "Epoch 147/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5502 - acc: 0.8096 - val_loss: 0.4750 - val_acc: 0.8553\n",
            "Epoch 148/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8097 - val_loss: 0.5589 - val_acc: 0.8079\n",
            "Epoch 149/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8117 - val_loss: 0.4857 - val_acc: 0.8465\n",
            "Epoch 150/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5482 - acc: 0.8120 - val_loss: 0.4607 - val_acc: 0.8600\n",
            "Epoch 151/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5492 - acc: 0.8113 - val_loss: 0.5143 - val_acc: 0.8406\n",
            "Epoch 152/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8093 - val_loss: 0.5711 - val_acc: 0.7876\n",
            "Epoch 153/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8089 - val_loss: 0.5266 - val_acc: 0.8253\n",
            "Epoch 154/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8095 - val_loss: 0.4737 - val_acc: 0.8508\n",
            "Epoch 155/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5484 - acc: 0.8106 - val_loss: 0.5367 - val_acc: 0.8217\n",
            "Epoch 156/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5496 - acc: 0.8104 - val_loss: 0.4992 - val_acc: 0.8476\n",
            "Epoch 157/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5527 - acc: 0.8087 - val_loss: 0.5205 - val_acc: 0.8205\n",
            "Epoch 158/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.8083 - val_loss: 0.6752 - val_acc: 0.7072\n",
            "Epoch 159/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5484 - acc: 0.8104 - val_loss: 0.5211 - val_acc: 0.8481\n",
            "Epoch 160/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5479 - acc: 0.8093 - val_loss: 0.5015 - val_acc: 0.8265\n",
            "Epoch 161/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5469 - acc: 0.8102 - val_loss: 0.5612 - val_acc: 0.8152\n",
            "Epoch 162/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5481 - acc: 0.8108 - val_loss: 0.6402 - val_acc: 0.7522\n",
            "Epoch 163/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8087 - val_loss: 0.4446 - val_acc: 0.8653\n",
            "Epoch 164/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5482 - acc: 0.8124 - val_loss: 0.5006 - val_acc: 0.8289\n",
            "Epoch 165/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5490 - acc: 0.8080 - val_loss: 0.4980 - val_acc: 0.8383\n",
            "Epoch 166/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5477 - acc: 0.8100 - val_loss: 0.5909 - val_acc: 0.7593\n",
            "Epoch 167/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5487 - acc: 0.8101 - val_loss: 0.5317 - val_acc: 0.8340\n",
            "Epoch 168/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5483 - acc: 0.8117 - val_loss: 0.6596 - val_acc: 0.7135\n",
            "Epoch 169/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8092 - val_loss: 0.4871 - val_acc: 0.8356\n",
            "Epoch 170/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5500 - acc: 0.8120 - val_loss: 0.5096 - val_acc: 0.8497\n",
            "Epoch 171/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8090 - val_loss: 0.5445 - val_acc: 0.8302\n",
            "Epoch 172/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8099 - val_loss: 0.5907 - val_acc: 0.7593\n",
            "Epoch 173/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5516 - acc: 0.8083 - val_loss: 0.5092 - val_acc: 0.8413\n",
            "Epoch 174/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5528 - acc: 0.8073 - val_loss: 0.5115 - val_acc: 0.8401\n",
            "Epoch 175/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8079 - val_loss: 0.6153 - val_acc: 0.7466\n",
            "Epoch 176/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5519 - acc: 0.8094 - val_loss: 0.5702 - val_acc: 0.7904\n",
            "Epoch 177/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5501 - acc: 0.8100 - val_loss: 0.5845 - val_acc: 0.8018\n",
            "Epoch 178/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8092 - val_loss: 0.5332 - val_acc: 0.8394\n",
            "Epoch 179/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5533 - acc: 0.8107 - val_loss: 0.5677 - val_acc: 0.8105\n",
            "Epoch 180/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5516 - acc: 0.8079 - val_loss: 0.5224 - val_acc: 0.8150\n",
            "Epoch 181/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.8101 - val_loss: 0.5411 - val_acc: 0.8164\n",
            "Epoch 182/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5547 - acc: 0.8090 - val_loss: 0.4809 - val_acc: 0.8589\n",
            "Epoch 183/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5546 - acc: 0.8113 - val_loss: 0.5520 - val_acc: 0.8191\n",
            "Epoch 184/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5530 - acc: 0.8077 - val_loss: 0.4773 - val_acc: 0.8587\n",
            "Epoch 185/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5512 - acc: 0.8110 - val_loss: 0.4919 - val_acc: 0.8390\n",
            "Epoch 186/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5517 - acc: 0.8108 - val_loss: 0.5332 - val_acc: 0.8356\n",
            "Epoch 187/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8103 - val_loss: 0.6065 - val_acc: 0.8019\n",
            "Epoch 188/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8082 - val_loss: 0.5423 - val_acc: 0.8264\n",
            "Epoch 189/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8103 - val_loss: 0.6388 - val_acc: 0.7352\n",
            "Epoch 190/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5524 - acc: 0.8094 - val_loss: 0.4700 - val_acc: 0.8564\n",
            "Epoch 191/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5506 - acc: 0.8104 - val_loss: 0.4894 - val_acc: 0.8513\n",
            "Epoch 192/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5515 - acc: 0.8107 - val_loss: 0.5848 - val_acc: 0.7994\n",
            "Epoch 193/1000\n",
            "240/240 [==============================] - 3s 12ms/step - loss: 0.5579 - acc: 0.8102 - val_loss: 0.4756 - val_acc: 0.8544\n",
            "Epoch 194/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5551 - acc: 0.8110 - val_loss: 0.5371 - val_acc: 0.8300\n",
            "Epoch 195/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5547 - acc: 0.8113 - val_loss: 0.5839 - val_acc: 0.7713\n",
            "Epoch 196/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5534 - acc: 0.8102 - val_loss: 0.6135 - val_acc: 0.7788\n",
            "Epoch 197/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5555 - acc: 0.8080 - val_loss: 0.5266 - val_acc: 0.8405\n",
            "Epoch 198/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5520 - acc: 0.8128 - val_loss: 0.5451 - val_acc: 0.8294\n",
            "Epoch 199/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8140 - val_loss: 0.5212 - val_acc: 0.8337\n",
            "Epoch 200/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5490 - acc: 0.8147 - val_loss: 0.5137 - val_acc: 0.8531\n",
            "Epoch 201/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8117 - val_loss: 0.5205 - val_acc: 0.8279\n",
            "Epoch 202/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5515 - acc: 0.8097 - val_loss: 0.5580 - val_acc: 0.7967\n",
            "Epoch 203/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5491 - acc: 0.8126 - val_loss: 0.5281 - val_acc: 0.8445\n",
            "Epoch 204/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5513 - acc: 0.8114 - val_loss: 0.5339 - val_acc: 0.8261\n",
            "Epoch 205/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8119 - val_loss: 0.5123 - val_acc: 0.8359\n",
            "Epoch 206/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5498 - acc: 0.8123 - val_loss: 0.5131 - val_acc: 0.8431\n",
            "Epoch 207/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8121 - val_loss: 0.5689 - val_acc: 0.8011\n",
            "Epoch 208/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8119 - val_loss: 0.5348 - val_acc: 0.8037\n",
            "Epoch 209/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8112 - val_loss: 0.5451 - val_acc: 0.8264\n",
            "Epoch 210/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5511 - acc: 0.8133 - val_loss: 0.5459 - val_acc: 0.8186\n",
            "Epoch 211/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5511 - acc: 0.8125 - val_loss: 0.6331 - val_acc: 0.7691\n",
            "Epoch 212/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5502 - acc: 0.8134 - val_loss: 0.5268 - val_acc: 0.8327\n",
            "Epoch 213/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5524 - acc: 0.8147 - val_loss: 0.5782 - val_acc: 0.7916\n",
            "Epoch 214/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5553 - acc: 0.8089 - val_loss: 0.5556 - val_acc: 0.8174\n",
            "Epoch 215/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8128 - val_loss: 0.6257 - val_acc: 0.7464\n",
            "Epoch 216/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8136 - val_loss: 0.4905 - val_acc: 0.8450\n",
            "Epoch 217/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8136 - val_loss: 0.6885 - val_acc: 0.7139\n",
            "Epoch 218/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8125 - val_loss: 0.5508 - val_acc: 0.8157\n",
            "Epoch 219/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5553 - acc: 0.8096 - val_loss: 0.5169 - val_acc: 0.8352\n",
            "Epoch 220/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5524 - acc: 0.8114 - val_loss: 0.5270 - val_acc: 0.8130\n",
            "Epoch 221/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5503 - acc: 0.8129 - val_loss: 0.6138 - val_acc: 0.7620\n",
            "Epoch 222/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5515 - acc: 0.8112 - val_loss: 0.5369 - val_acc: 0.8285\n",
            "Epoch 223/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8129 - val_loss: 0.6365 - val_acc: 0.7203\n",
            "Epoch 224/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5533 - acc: 0.8123 - val_loss: 0.5801 - val_acc: 0.7861\n",
            "Epoch 225/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5511 - acc: 0.8147 - val_loss: 0.5327 - val_acc: 0.8378\n",
            "Epoch 226/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8139 - val_loss: 0.5585 - val_acc: 0.8007\n",
            "Epoch 227/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8127 - val_loss: 0.5286 - val_acc: 0.8383\n",
            "Epoch 228/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8119 - val_loss: 0.5023 - val_acc: 0.8369\n",
            "Epoch 229/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5506 - acc: 0.8137 - val_loss: 0.5936 - val_acc: 0.7792\n",
            "Epoch 230/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5529 - acc: 0.8093 - val_loss: 0.5501 - val_acc: 0.8074\n",
            "Epoch 231/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5498 - acc: 0.8130 - val_loss: 0.5355 - val_acc: 0.8323\n",
            "Epoch 232/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8126 - val_loss: 0.5609 - val_acc: 0.8158\n",
            "Epoch 233/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8134 - val_loss: 0.6569 - val_acc: 0.7206\n",
            "Epoch 234/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8121 - val_loss: 0.5591 - val_acc: 0.7971\n",
            "Epoch 235/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5494 - acc: 0.8130 - val_loss: 0.6069 - val_acc: 0.7792\n",
            "Epoch 236/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5506 - acc: 0.8124 - val_loss: 0.5162 - val_acc: 0.8192\n",
            "Epoch 237/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5538 - acc: 0.8109 - val_loss: 0.5033 - val_acc: 0.8314\n",
            "Epoch 238/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5518 - acc: 0.8120 - val_loss: 0.5772 - val_acc: 0.8173\n",
            "Epoch 239/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5516 - acc: 0.8127 - val_loss: 0.4853 - val_acc: 0.8407\n",
            "Epoch 240/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8119 - val_loss: 0.6147 - val_acc: 0.7767\n",
            "Epoch 241/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5515 - acc: 0.8136 - val_loss: 0.4952 - val_acc: 0.8441\n",
            "Epoch 242/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5535 - acc: 0.8106 - val_loss: 0.5312 - val_acc: 0.8156\n",
            "Epoch 243/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5542 - acc: 0.8107 - val_loss: 0.6284 - val_acc: 0.7710\n",
            "Epoch 244/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8123 - val_loss: 0.4977 - val_acc: 0.8390\n",
            "Epoch 245/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5498 - acc: 0.8142 - val_loss: 0.4542 - val_acc: 0.8602\n",
            "Epoch 246/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5496 - acc: 0.8143 - val_loss: 0.5592 - val_acc: 0.8066\n",
            "Epoch 247/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8140 - val_loss: 0.5218 - val_acc: 0.8243\n",
            "Epoch 248/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5512 - acc: 0.8160 - val_loss: 0.5734 - val_acc: 0.8166\n",
            "Epoch 249/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8139 - val_loss: 0.5623 - val_acc: 0.8048\n",
            "Epoch 250/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8140 - val_loss: 0.5121 - val_acc: 0.8378\n",
            "Epoch 251/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8114 - val_loss: 0.4801 - val_acc: 0.8401\n",
            "Epoch 252/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5521 - acc: 0.8127 - val_loss: 0.5080 - val_acc: 0.8402\n",
            "Epoch 253/1000\n",
            "240/240 [==============================] - 1s 5ms/step - loss: 0.5532 - acc: 0.8130 - val_loss: 0.4972 - val_acc: 0.8489\n",
            "Epoch 254/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8128 - val_loss: 0.5486 - val_acc: 0.8062\n",
            "Epoch 255/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5497 - acc: 0.8124 - val_loss: 0.6494 - val_acc: 0.7615\n",
            "Epoch 256/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5534 - acc: 0.8106 - val_loss: 0.6126 - val_acc: 0.7752\n",
            "Epoch 257/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5525 - acc: 0.8131 - val_loss: 0.5518 - val_acc: 0.8320\n",
            "Epoch 258/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5517 - acc: 0.8118 - val_loss: 0.6032 - val_acc: 0.7797\n",
            "Epoch 259/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5484 - acc: 0.8159 - val_loss: 0.5770 - val_acc: 0.7885\n",
            "Epoch 260/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8154 - val_loss: 0.5914 - val_acc: 0.7944\n",
            "Epoch 261/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8136 - val_loss: 0.4729 - val_acc: 0.8646\n",
            "Epoch 262/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8128 - val_loss: 0.5563 - val_acc: 0.7895\n",
            "Epoch 263/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5494 - acc: 0.8122 - val_loss: 0.5646 - val_acc: 0.8183\n",
            "Epoch 264/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5514 - acc: 0.8135 - val_loss: 0.5309 - val_acc: 0.8325\n",
            "Epoch 265/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8136 - val_loss: 0.4756 - val_acc: 0.8538\n",
            "Epoch 266/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5511 - acc: 0.8135 - val_loss: 0.5557 - val_acc: 0.8269\n",
            "Epoch 267/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8156 - val_loss: 0.5176 - val_acc: 0.8316\n",
            "Epoch 268/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5527 - acc: 0.8113 - val_loss: 0.5274 - val_acc: 0.8204\n",
            "Epoch 269/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8159 - val_loss: 0.5859 - val_acc: 0.7998\n",
            "Epoch 270/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8124 - val_loss: 0.5960 - val_acc: 0.7715\n",
            "Epoch 271/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5496 - acc: 0.8103 - val_loss: 0.5108 - val_acc: 0.8389\n",
            "Epoch 272/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5520 - acc: 0.8125 - val_loss: 0.6486 - val_acc: 0.7592\n",
            "Epoch 273/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5512 - acc: 0.8135 - val_loss: 0.4924 - val_acc: 0.8381\n",
            "Epoch 274/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8161 - val_loss: 0.6664 - val_acc: 0.7152\n",
            "Epoch 275/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5496 - acc: 0.8133 - val_loss: 0.5166 - val_acc: 0.8204\n",
            "Epoch 276/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8127 - val_loss: 0.6087 - val_acc: 0.7632\n",
            "Epoch 277/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5514 - acc: 0.8122 - val_loss: 0.5271 - val_acc: 0.8213\n",
            "Epoch 278/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.8119 - val_loss: 0.5245 - val_acc: 0.8453\n",
            "Epoch 279/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5525 - acc: 0.8135 - val_loss: 0.5361 - val_acc: 0.8457\n",
            "Epoch 280/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5512 - acc: 0.8119 - val_loss: 0.5983 - val_acc: 0.7993\n",
            "Epoch 281/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5536 - acc: 0.8108 - val_loss: 0.4897 - val_acc: 0.8572\n",
            "Epoch 282/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8131 - val_loss: 0.5536 - val_acc: 0.8029\n",
            "Epoch 283/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5496 - acc: 0.8150 - val_loss: 0.5713 - val_acc: 0.7597\n",
            "Epoch 284/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8137 - val_loss: 0.5819 - val_acc: 0.7739\n",
            "Epoch 285/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5471 - acc: 0.8133 - val_loss: 0.5793 - val_acc: 0.8064\n",
            "Epoch 286/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8137 - val_loss: 0.5728 - val_acc: 0.7975\n",
            "Epoch 287/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5519 - acc: 0.8117 - val_loss: 0.6239 - val_acc: 0.7848\n",
            "Epoch 288/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8139 - val_loss: 0.5335 - val_acc: 0.8236\n",
            "Epoch 289/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5517 - acc: 0.8115 - val_loss: 0.5168 - val_acc: 0.8353\n",
            "Epoch 290/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5510 - acc: 0.8123 - val_loss: 0.5704 - val_acc: 0.7890\n",
            "Epoch 291/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8133 - val_loss: 0.6304 - val_acc: 0.7707\n",
            "Epoch 292/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8144 - val_loss: 0.5551 - val_acc: 0.8044\n",
            "Epoch 293/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8129 - val_loss: 0.5436 - val_acc: 0.8272\n",
            "Epoch 294/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8141 - val_loss: 0.6014 - val_acc: 0.7714\n",
            "Epoch 295/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5532 - acc: 0.8097 - val_loss: 0.5871 - val_acc: 0.7853\n",
            "Epoch 296/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5485 - acc: 0.8159 - val_loss: 0.6013 - val_acc: 0.7875\n",
            "Epoch 297/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8144 - val_loss: 0.4980 - val_acc: 0.8574\n",
            "Epoch 298/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5511 - acc: 0.8132 - val_loss: 0.5624 - val_acc: 0.8297\n",
            "Epoch 299/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8124 - val_loss: 0.5690 - val_acc: 0.7968\n",
            "Epoch 300/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8109 - val_loss: 0.5214 - val_acc: 0.8410\n",
            "Epoch 301/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5523 - acc: 0.8115 - val_loss: 0.5600 - val_acc: 0.8005\n",
            "Epoch 302/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5515 - acc: 0.8116 - val_loss: 0.5294 - val_acc: 0.8224\n",
            "Epoch 303/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5517 - acc: 0.8132 - val_loss: 0.5744 - val_acc: 0.8202\n",
            "Epoch 304/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5527 - acc: 0.8146 - val_loss: 0.5745 - val_acc: 0.7909\n",
            "Epoch 305/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8136 - val_loss: 0.5020 - val_acc: 0.8329\n",
            "Epoch 306/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5515 - acc: 0.8124 - val_loss: 0.5478 - val_acc: 0.8109\n",
            "Epoch 307/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5508 - acc: 0.8100 - val_loss: 0.5153 - val_acc: 0.8311\n",
            "Epoch 308/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8142 - val_loss: 0.4990 - val_acc: 0.8457\n",
            "Epoch 309/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8142 - val_loss: 0.5832 - val_acc: 0.7728\n",
            "Epoch 310/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8131 - val_loss: 0.5458 - val_acc: 0.8181\n",
            "Epoch 311/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5502 - acc: 0.8117 - val_loss: 0.5352 - val_acc: 0.8246\n",
            "Epoch 312/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5586 - acc: 0.8061 - val_loss: 0.4934 - val_acc: 0.8480\n",
            "Epoch 313/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5525 - acc: 0.8120 - val_loss: 0.5826 - val_acc: 0.7853\n",
            "Epoch 314/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5514 - acc: 0.8109 - val_loss: 0.5169 - val_acc: 0.8432\n",
            "Epoch 315/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5524 - acc: 0.8111 - val_loss: 0.5299 - val_acc: 0.8389\n",
            "Epoch 316/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5496 - acc: 0.8131 - val_loss: 0.5502 - val_acc: 0.8044\n",
            "Epoch 317/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8109 - val_loss: 0.5369 - val_acc: 0.8203\n",
            "Epoch 318/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5534 - acc: 0.8112 - val_loss: 0.6282 - val_acc: 0.7406\n",
            "Epoch 319/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5510 - acc: 0.8131 - val_loss: 0.5549 - val_acc: 0.7983\n",
            "Epoch 320/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5492 - acc: 0.8141 - val_loss: 0.5264 - val_acc: 0.8270\n",
            "Epoch 321/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8122 - val_loss: 0.5281 - val_acc: 0.8413\n",
            "Epoch 322/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5513 - acc: 0.8123 - val_loss: 0.5256 - val_acc: 0.8346\n",
            "Epoch 323/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5488 - acc: 0.8149 - val_loss: 0.4986 - val_acc: 0.8186\n",
            "Epoch 324/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5507 - acc: 0.8114 - val_loss: 0.4969 - val_acc: 0.8508\n",
            "Epoch 325/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8104 - val_loss: 0.5427 - val_acc: 0.8016\n",
            "Epoch 326/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5496 - acc: 0.8145 - val_loss: 0.6030 - val_acc: 0.7876\n",
            "Epoch 327/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5482 - acc: 0.8138 - val_loss: 0.5119 - val_acc: 0.8247\n",
            "Epoch 328/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5497 - acc: 0.8119 - val_loss: 0.4988 - val_acc: 0.8296\n",
            "Epoch 329/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5485 - acc: 0.8122 - val_loss: 0.5973 - val_acc: 0.7779\n",
            "Epoch 330/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5508 - acc: 0.8112 - val_loss: 0.4932 - val_acc: 0.8536\n",
            "Epoch 331/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5500 - acc: 0.8144 - val_loss: 0.5505 - val_acc: 0.7950\n",
            "Epoch 332/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5534 - acc: 0.8116 - val_loss: 0.5312 - val_acc: 0.8370\n",
            "Epoch 333/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5521 - acc: 0.8136 - val_loss: 0.5708 - val_acc: 0.8153\n",
            "Epoch 334/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5537 - acc: 0.8120 - val_loss: 0.5771 - val_acc: 0.8098\n",
            "Epoch 335/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5526 - acc: 0.8127 - val_loss: 0.5990 - val_acc: 0.7821\n",
            "Epoch 336/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5498 - acc: 0.8129 - val_loss: 0.5308 - val_acc: 0.8160\n",
            "Epoch 337/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8121 - val_loss: 0.5454 - val_acc: 0.8207\n",
            "Epoch 338/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5531 - acc: 0.8127 - val_loss: 0.5474 - val_acc: 0.8189\n",
            "Epoch 339/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5515 - acc: 0.8137 - val_loss: 0.4913 - val_acc: 0.8493\n",
            "Epoch 340/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5483 - acc: 0.8145 - val_loss: 0.5819 - val_acc: 0.8053\n",
            "Epoch 341/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5542 - acc: 0.8108 - val_loss: 0.6143 - val_acc: 0.7695\n",
            "Epoch 342/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.8136 - val_loss: 0.6041 - val_acc: 0.7571\n",
            "Epoch 343/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.8104 - val_loss: 0.5256 - val_acc: 0.8337\n",
            "Epoch 344/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8130 - val_loss: 0.5650 - val_acc: 0.8297\n",
            "Epoch 345/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8123 - val_loss: 0.5618 - val_acc: 0.8100\n",
            "Epoch 346/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8129 - val_loss: 0.5594 - val_acc: 0.7845\n",
            "Epoch 347/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5534 - acc: 0.8101 - val_loss: 0.6402 - val_acc: 0.7472\n",
            "Epoch 348/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5568 - acc: 0.8100 - val_loss: 0.5806 - val_acc: 0.7915\n",
            "Epoch 349/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5522 - acc: 0.8125 - val_loss: 0.5524 - val_acc: 0.8346\n",
            "Epoch 350/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8127 - val_loss: 0.5656 - val_acc: 0.7852\n",
            "Epoch 351/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8121 - val_loss: 0.5468 - val_acc: 0.8046\n",
            "Epoch 352/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8133 - val_loss: 0.5183 - val_acc: 0.8422\n",
            "Epoch 353/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5497 - acc: 0.8141 - val_loss: 0.4935 - val_acc: 0.8529\n",
            "Epoch 354/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8161 - val_loss: 0.6164 - val_acc: 0.7599\n",
            "Epoch 355/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8150 - val_loss: 0.6136 - val_acc: 0.7390\n",
            "Epoch 356/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5495 - acc: 0.8121 - val_loss: 0.5416 - val_acc: 0.8140\n",
            "Epoch 357/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5499 - acc: 0.8115 - val_loss: 0.5711 - val_acc: 0.7914\n",
            "Epoch 358/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5522 - acc: 0.8123 - val_loss: 0.5063 - val_acc: 0.8397\n",
            "Epoch 359/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8108 - val_loss: 0.5246 - val_acc: 0.8403\n",
            "Epoch 360/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5487 - acc: 0.8129 - val_loss: 0.6283 - val_acc: 0.7476\n",
            "Epoch 361/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5522 - acc: 0.8122 - val_loss: 0.5568 - val_acc: 0.8047\n",
            "Epoch 362/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8138 - val_loss: 0.6620 - val_acc: 0.7501\n",
            "Epoch 363/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8128 - val_loss: 0.5361 - val_acc: 0.8232\n",
            "Epoch 364/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5484 - acc: 0.8139 - val_loss: 0.6013 - val_acc: 0.7842\n",
            "Epoch 365/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5510 - acc: 0.8099 - val_loss: 0.5321 - val_acc: 0.8190\n",
            "Epoch 366/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5494 - acc: 0.8152 - val_loss: 0.5745 - val_acc: 0.8050\n",
            "Epoch 367/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8138 - val_loss: 0.4832 - val_acc: 0.8526\n",
            "Epoch 368/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8123 - val_loss: 0.5502 - val_acc: 0.8146\n",
            "Epoch 369/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5466 - acc: 0.8143 - val_loss: 0.5337 - val_acc: 0.8216\n",
            "Epoch 370/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8119 - val_loss: 0.5114 - val_acc: 0.8438\n",
            "Epoch 371/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8121 - val_loss: 0.5888 - val_acc: 0.8061\n",
            "Epoch 372/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8139 - val_loss: 0.5479 - val_acc: 0.8254\n",
            "Epoch 373/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8137 - val_loss: 0.5531 - val_acc: 0.8218\n",
            "Epoch 374/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5519 - acc: 0.8138 - val_loss: 0.5218 - val_acc: 0.8207\n",
            "Epoch 375/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5489 - acc: 0.8125 - val_loss: 0.5230 - val_acc: 0.8352\n",
            "Epoch 376/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5494 - acc: 0.8150 - val_loss: 0.6232 - val_acc: 0.7558\n",
            "Epoch 377/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5500 - acc: 0.8134 - val_loss: 0.5781 - val_acc: 0.7841\n",
            "Epoch 378/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8126 - val_loss: 0.4985 - val_acc: 0.8446\n",
            "Epoch 379/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8130 - val_loss: 0.5407 - val_acc: 0.8156\n",
            "Epoch 380/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8132 - val_loss: 0.5977 - val_acc: 0.7782\n",
            "Epoch 381/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8139 - val_loss: 0.6034 - val_acc: 0.7744\n",
            "Epoch 382/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5489 - acc: 0.8134 - val_loss: 0.5646 - val_acc: 0.8063\n",
            "Epoch 383/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5489 - acc: 0.8122 - val_loss: 0.4389 - val_acc: 0.8537\n",
            "Epoch 384/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8127 - val_loss: 0.5770 - val_acc: 0.7898\n",
            "Epoch 385/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8115 - val_loss: 0.5179 - val_acc: 0.8346\n",
            "Epoch 386/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5541 - acc: 0.8125 - val_loss: 0.4913 - val_acc: 0.8420\n",
            "Epoch 387/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5577 - acc: 0.8161 - val_loss: 0.5841 - val_acc: 0.7951\n",
            "Epoch 388/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5541 - acc: 0.8137 - val_loss: 0.5331 - val_acc: 0.8195\n",
            "Epoch 389/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5547 - acc: 0.8106 - val_loss: 0.5245 - val_acc: 0.8143\n",
            "Epoch 390/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5501 - acc: 0.8174 - val_loss: 0.5905 - val_acc: 0.7980\n",
            "Epoch 391/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5521 - acc: 0.8140 - val_loss: 0.5529 - val_acc: 0.8152\n",
            "Epoch 392/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5518 - acc: 0.8126 - val_loss: 0.7027 - val_acc: 0.6770\n",
            "Epoch 393/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8132 - val_loss: 0.5358 - val_acc: 0.8418\n",
            "Epoch 394/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5515 - acc: 0.8135 - val_loss: 0.5411 - val_acc: 0.8119\n",
            "Epoch 395/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5516 - acc: 0.8120 - val_loss: 0.5645 - val_acc: 0.8173\n",
            "Epoch 396/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8150 - val_loss: 0.5877 - val_acc: 0.7866\n",
            "Epoch 397/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8134 - val_loss: 0.6783 - val_acc: 0.6950\n",
            "Epoch 398/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5508 - acc: 0.8148 - val_loss: 0.5656 - val_acc: 0.8128\n",
            "Epoch 399/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5511 - acc: 0.8126 - val_loss: 0.6194 - val_acc: 0.7644\n",
            "Epoch 400/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8139 - val_loss: 0.6384 - val_acc: 0.7403\n",
            "Epoch 401/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8131 - val_loss: 0.5012 - val_acc: 0.8341\n",
            "Epoch 402/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5519 - acc: 0.8105 - val_loss: 0.4945 - val_acc: 0.8317\n",
            "Epoch 403/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8116 - val_loss: 0.5561 - val_acc: 0.8191\n",
            "Epoch 404/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5491 - acc: 0.8145 - val_loss: 0.5947 - val_acc: 0.7929\n",
            "Epoch 405/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8123 - val_loss: 0.4802 - val_acc: 0.8342\n",
            "Epoch 406/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5502 - acc: 0.8128 - val_loss: 0.5414 - val_acc: 0.8222\n",
            "Epoch 407/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5493 - acc: 0.8130 - val_loss: 0.6088 - val_acc: 0.7729\n",
            "Epoch 408/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5488 - acc: 0.8145 - val_loss: 0.5234 - val_acc: 0.8218\n",
            "Epoch 409/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8145 - val_loss: 0.5817 - val_acc: 0.8044\n",
            "Epoch 410/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5498 - acc: 0.8146 - val_loss: 0.5219 - val_acc: 0.8320\n",
            "Epoch 411/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8125 - val_loss: 0.5151 - val_acc: 0.8356\n",
            "Epoch 412/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8123 - val_loss: 0.6184 - val_acc: 0.7661\n",
            "Epoch 413/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8131 - val_loss: 0.5968 - val_acc: 0.7673\n",
            "Epoch 414/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5499 - acc: 0.8126 - val_loss: 0.5263 - val_acc: 0.8246\n",
            "Epoch 415/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5503 - acc: 0.8111 - val_loss: 0.5768 - val_acc: 0.7900\n",
            "Epoch 416/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5496 - acc: 0.8138 - val_loss: 0.5031 - val_acc: 0.8281\n",
            "Epoch 417/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5518 - acc: 0.8122 - val_loss: 0.6140 - val_acc: 0.7841\n",
            "Epoch 418/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8116 - val_loss: 0.5484 - val_acc: 0.8129\n",
            "Epoch 419/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8112 - val_loss: 0.5122 - val_acc: 0.8383\n",
            "Epoch 420/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5512 - acc: 0.8116 - val_loss: 0.5556 - val_acc: 0.7960\n",
            "Epoch 421/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5511 - acc: 0.8126 - val_loss: 0.5496 - val_acc: 0.8290\n",
            "Epoch 422/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8145 - val_loss: 0.5022 - val_acc: 0.8552\n",
            "Epoch 423/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8143 - val_loss: 0.5353 - val_acc: 0.8231\n",
            "Epoch 424/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5491 - acc: 0.8137 - val_loss: 0.5463 - val_acc: 0.8356\n",
            "Epoch 425/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5540 - acc: 0.8091 - val_loss: 0.4672 - val_acc: 0.8551\n",
            "Epoch 426/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5509 - acc: 0.8109 - val_loss: 0.5400 - val_acc: 0.8092\n",
            "Epoch 427/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5495 - acc: 0.8140 - val_loss: 0.6008 - val_acc: 0.7780\n",
            "Epoch 428/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8129 - val_loss: 0.5442 - val_acc: 0.7990\n",
            "Epoch 429/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8138 - val_loss: 0.6465 - val_acc: 0.7489\n",
            "Epoch 430/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8118 - val_loss: 0.5211 - val_acc: 0.8254\n",
            "Epoch 431/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8125 - val_loss: 0.4964 - val_acc: 0.8442\n",
            "Epoch 432/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5502 - acc: 0.8131 - val_loss: 0.5256 - val_acc: 0.8252\n",
            "Epoch 433/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5489 - acc: 0.8121 - val_loss: 0.5688 - val_acc: 0.7751\n",
            "Epoch 434/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8125 - val_loss: 0.5783 - val_acc: 0.8176\n",
            "Epoch 435/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5505 - acc: 0.8122 - val_loss: 0.5132 - val_acc: 0.8251\n",
            "Epoch 436/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5492 - acc: 0.8149 - val_loss: 0.5343 - val_acc: 0.8173\n",
            "Epoch 437/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5489 - acc: 0.8147 - val_loss: 0.5533 - val_acc: 0.8342\n",
            "Epoch 438/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8132 - val_loss: 0.5295 - val_acc: 0.8168\n",
            "Epoch 439/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8105 - val_loss: 0.6763 - val_acc: 0.7218\n",
            "Epoch 440/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5498 - acc: 0.8142 - val_loss: 0.5783 - val_acc: 0.8058\n",
            "Epoch 441/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5485 - acc: 0.8152 - val_loss: 0.5083 - val_acc: 0.8275\n",
            "Epoch 442/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5499 - acc: 0.8116 - val_loss: 0.4797 - val_acc: 0.8576\n",
            "Epoch 443/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5511 - acc: 0.8130 - val_loss: 0.6026 - val_acc: 0.7538\n",
            "Epoch 444/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5494 - acc: 0.8132 - val_loss: 0.6275 - val_acc: 0.7516\n",
            "Epoch 445/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8100 - val_loss: 0.4965 - val_acc: 0.8544\n",
            "Epoch 446/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8133 - val_loss: 0.5407 - val_acc: 0.8266\n",
            "Epoch 447/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5482 - acc: 0.8142 - val_loss: 0.5717 - val_acc: 0.8027\n",
            "Epoch 448/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8122 - val_loss: 0.5689 - val_acc: 0.8131\n",
            "Epoch 449/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5534 - acc: 0.8096 - val_loss: 0.5747 - val_acc: 0.7780\n",
            "Epoch 450/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5509 - acc: 0.8127 - val_loss: 0.6869 - val_acc: 0.6915\n",
            "Epoch 451/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5525 - acc: 0.8072 - val_loss: 0.4896 - val_acc: 0.8386\n",
            "Epoch 452/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5499 - acc: 0.8107 - val_loss: 0.5511 - val_acc: 0.8043\n",
            "Epoch 453/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8133 - val_loss: 0.5233 - val_acc: 0.8148\n",
            "Epoch 454/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8127 - val_loss: 0.5387 - val_acc: 0.8173\n",
            "Epoch 455/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5502 - acc: 0.8115 - val_loss: 0.5145 - val_acc: 0.8364\n",
            "Epoch 456/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5507 - acc: 0.8121 - val_loss: 0.5547 - val_acc: 0.8045\n",
            "Epoch 457/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5502 - acc: 0.8141 - val_loss: 0.5593 - val_acc: 0.8224\n",
            "Epoch 458/1000\n",
            "240/240 [==============================] - 3s 12ms/step - loss: 0.5491 - acc: 0.8151 - val_loss: 0.5056 - val_acc: 0.8332\n",
            "Epoch 459/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5493 - acc: 0.8126 - val_loss: 0.5560 - val_acc: 0.8303\n",
            "Epoch 460/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5504 - acc: 0.8110 - val_loss: 0.5986 - val_acc: 0.8101\n",
            "Epoch 461/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5516 - acc: 0.8112 - val_loss: 0.5674 - val_acc: 0.8060\n",
            "Epoch 462/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5505 - acc: 0.8125 - val_loss: 0.5215 - val_acc: 0.8432\n",
            "Epoch 463/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5519 - acc: 0.8128 - val_loss: 0.5217 - val_acc: 0.8314\n",
            "Epoch 464/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5490 - acc: 0.8129 - val_loss: 0.5519 - val_acc: 0.8089\n",
            "Epoch 465/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5493 - acc: 0.8150 - val_loss: 0.5372 - val_acc: 0.8360\n",
            "Epoch 466/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8155 - val_loss: 0.5332 - val_acc: 0.8230\n",
            "Epoch 467/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5500 - acc: 0.8109 - val_loss: 0.5183 - val_acc: 0.8261\n",
            "Epoch 468/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5482 - acc: 0.8150 - val_loss: 0.5712 - val_acc: 0.8221\n",
            "Epoch 469/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5521 - acc: 0.8090 - val_loss: 0.4617 - val_acc: 0.8548\n",
            "Epoch 470/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5503 - acc: 0.8130 - val_loss: 0.5497 - val_acc: 0.8062\n",
            "Epoch 471/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5490 - acc: 0.8125 - val_loss: 0.5693 - val_acc: 0.8019\n",
            "Epoch 472/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5505 - acc: 0.8108 - val_loss: 0.4730 - val_acc: 0.8667\n",
            "Epoch 473/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5507 - acc: 0.8122 - val_loss: 0.5555 - val_acc: 0.7957\n",
            "Epoch 474/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8125 - val_loss: 0.5150 - val_acc: 0.8450\n",
            "Epoch 475/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5502 - acc: 0.8113 - val_loss: 0.5473 - val_acc: 0.8312\n",
            "Epoch 476/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8148 - val_loss: 0.5638 - val_acc: 0.8068\n",
            "Epoch 477/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5502 - acc: 0.8165 - val_loss: 0.5197 - val_acc: 0.8327\n",
            "Epoch 478/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5490 - acc: 0.8165 - val_loss: 0.5839 - val_acc: 0.8031\n",
            "Epoch 479/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8137 - val_loss: 0.5942 - val_acc: 0.8031\n",
            "Epoch 480/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5499 - acc: 0.8112 - val_loss: 0.5175 - val_acc: 0.8323\n",
            "Epoch 481/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5497 - acc: 0.8128 - val_loss: 0.5288 - val_acc: 0.8229\n",
            "Epoch 482/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5502 - acc: 0.8116 - val_loss: 0.6671 - val_acc: 0.7327\n",
            "Epoch 483/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8119 - val_loss: 0.5737 - val_acc: 0.8023\n",
            "Epoch 484/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5509 - acc: 0.8126 - val_loss: 0.6947 - val_acc: 0.6708\n",
            "Epoch 485/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8139 - val_loss: 0.5856 - val_acc: 0.7850\n",
            "Epoch 486/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5524 - acc: 0.8115 - val_loss: 0.5154 - val_acc: 0.8496\n",
            "Epoch 487/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5506 - acc: 0.8119 - val_loss: 0.5567 - val_acc: 0.8158\n",
            "Epoch 488/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8158 - val_loss: 0.5822 - val_acc: 0.8173\n",
            "Epoch 489/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5505 - acc: 0.8125 - val_loss: 0.5342 - val_acc: 0.8381\n",
            "Epoch 490/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5502 - acc: 0.8144 - val_loss: 0.5274 - val_acc: 0.8053\n",
            "Epoch 491/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5486 - acc: 0.8127 - val_loss: 0.5226 - val_acc: 0.8387\n",
            "Epoch 492/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8120 - val_loss: 0.5296 - val_acc: 0.8332\n",
            "Epoch 493/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8132 - val_loss: 0.4957 - val_acc: 0.8510\n",
            "Epoch 494/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5537 - acc: 0.8124 - val_loss: 0.5929 - val_acc: 0.8021\n",
            "Epoch 495/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5513 - acc: 0.8137 - val_loss: 0.6126 - val_acc: 0.7903\n",
            "Epoch 496/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5510 - acc: 0.8124 - val_loss: 0.5705 - val_acc: 0.8102\n",
            "Epoch 497/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5513 - acc: 0.8118 - val_loss: 0.6243 - val_acc: 0.7387\n",
            "Epoch 498/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5505 - acc: 0.8146 - val_loss: 0.4938 - val_acc: 0.8518\n",
            "Epoch 499/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8103 - val_loss: 0.5667 - val_acc: 0.7936\n",
            "Epoch 500/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5498 - acc: 0.8125 - val_loss: 0.5989 - val_acc: 0.7907\n",
            "Epoch 501/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5492 - acc: 0.8127 - val_loss: 0.6149 - val_acc: 0.7484\n",
            "Epoch 502/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5520 - acc: 0.8115 - val_loss: 0.5351 - val_acc: 0.8154\n",
            "Epoch 503/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5514 - acc: 0.8123 - val_loss: 0.6233 - val_acc: 0.7979\n",
            "Epoch 504/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5507 - acc: 0.8128 - val_loss: 0.5005 - val_acc: 0.8377\n",
            "Epoch 505/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5506 - acc: 0.8155 - val_loss: 0.5254 - val_acc: 0.8203\n",
            "Epoch 506/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5492 - acc: 0.8127 - val_loss: 0.5590 - val_acc: 0.8167\n",
            "Epoch 507/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5491 - acc: 0.8132 - val_loss: 0.5430 - val_acc: 0.8306\n",
            "Epoch 508/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8119 - val_loss: 0.5118 - val_acc: 0.8359\n",
            "Epoch 509/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5494 - acc: 0.8147 - val_loss: 0.5841 - val_acc: 0.7772\n",
            "Epoch 510/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5481 - acc: 0.8142 - val_loss: 0.6830 - val_acc: 0.7100\n",
            "Epoch 511/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8140 - val_loss: 0.5952 - val_acc: 0.7934\n",
            "Epoch 512/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8117 - val_loss: 0.6170 - val_acc: 0.7407\n",
            "Epoch 513/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5500 - acc: 0.8128 - val_loss: 0.5577 - val_acc: 0.8141\n",
            "Epoch 514/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5511 - acc: 0.8092 - val_loss: 0.5148 - val_acc: 0.8363\n",
            "Epoch 515/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5483 - acc: 0.8151 - val_loss: 0.5344 - val_acc: 0.8361\n",
            "Epoch 516/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5505 - acc: 0.8091 - val_loss: 0.5215 - val_acc: 0.8300\n",
            "Epoch 517/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8134 - val_loss: 0.6058 - val_acc: 0.7826\n",
            "Epoch 518/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8133 - val_loss: 0.5321 - val_acc: 0.8204\n",
            "Epoch 519/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8112 - val_loss: 0.5516 - val_acc: 0.8167\n",
            "Epoch 520/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5487 - acc: 0.8124 - val_loss: 0.6091 - val_acc: 0.7922\n",
            "Epoch 521/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5490 - acc: 0.8113 - val_loss: 0.6650 - val_acc: 0.7090\n",
            "Epoch 522/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5493 - acc: 0.8125 - val_loss: 0.5691 - val_acc: 0.7788\n",
            "Epoch 523/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5488 - acc: 0.8122 - val_loss: 0.5446 - val_acc: 0.8277\n",
            "Epoch 524/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5479 - acc: 0.8146 - val_loss: 0.5461 - val_acc: 0.8095\n",
            "Epoch 525/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5519 - acc: 0.8115 - val_loss: 0.5499 - val_acc: 0.8114\n",
            "Epoch 526/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5503 - acc: 0.8128 - val_loss: 0.5604 - val_acc: 0.8095\n",
            "Epoch 527/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5601 - acc: 0.8131 - val_loss: 0.5528 - val_acc: 0.8012\n",
            "Epoch 528/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5560 - acc: 0.8159 - val_loss: 0.4955 - val_acc: 0.8495\n",
            "Epoch 529/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5523 - acc: 0.8141 - val_loss: 0.6577 - val_acc: 0.7411\n",
            "Epoch 530/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5505 - acc: 0.8143 - val_loss: 0.5958 - val_acc: 0.7872\n",
            "Epoch 531/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5501 - acc: 0.8139 - val_loss: 0.5508 - val_acc: 0.8129\n",
            "Epoch 532/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5495 - acc: 0.8154 - val_loss: 0.6114 - val_acc: 0.7657\n",
            "Epoch 533/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5495 - acc: 0.8130 - val_loss: 0.5738 - val_acc: 0.7882\n",
            "Epoch 534/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8132 - val_loss: 0.5913 - val_acc: 0.7851\n",
            "Epoch 535/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5493 - acc: 0.8137 - val_loss: 0.5298 - val_acc: 0.8334\n",
            "Epoch 536/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8126 - val_loss: 0.5524 - val_acc: 0.8146\n",
            "Epoch 537/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5534 - acc: 0.8118 - val_loss: 0.6000 - val_acc: 0.7911\n",
            "Epoch 538/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5522 - acc: 0.8125 - val_loss: 0.5593 - val_acc: 0.8260\n",
            "Epoch 539/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5516 - acc: 0.8139 - val_loss: 0.6085 - val_acc: 0.7766\n",
            "Epoch 540/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5492 - acc: 0.8146 - val_loss: 0.5366 - val_acc: 0.8288\n",
            "Epoch 541/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5530 - acc: 0.8110 - val_loss: 0.6953 - val_acc: 0.6722\n",
            "Epoch 542/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5508 - acc: 0.8124 - val_loss: 0.5727 - val_acc: 0.7896\n",
            "Epoch 543/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5503 - acc: 0.8114 - val_loss: 0.5348 - val_acc: 0.8116\n",
            "Epoch 544/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5509 - acc: 0.8119 - val_loss: 0.5469 - val_acc: 0.8140\n",
            "Epoch 545/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5516 - acc: 0.8113 - val_loss: 0.5404 - val_acc: 0.8369\n",
            "Epoch 546/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8141 - val_loss: 0.5928 - val_acc: 0.8123\n",
            "Epoch 547/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5529 - acc: 0.8106 - val_loss: 0.6491 - val_acc: 0.7089\n",
            "Epoch 548/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5490 - acc: 0.8123 - val_loss: 0.5966 - val_acc: 0.7925\n",
            "Epoch 549/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5614 - acc: 0.8020 - val_loss: 0.7199 - val_acc: 0.6097\n",
            "Epoch 550/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8113 - val_loss: 0.5851 - val_acc: 0.7979\n",
            "Epoch 551/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5483 - acc: 0.8138 - val_loss: 0.6990 - val_acc: 0.6150\n",
            "Epoch 552/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5508 - acc: 0.8117 - val_loss: 0.5194 - val_acc: 0.8105\n",
            "Epoch 553/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5498 - acc: 0.8125 - val_loss: 0.4936 - val_acc: 0.8448\n",
            "Epoch 554/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5487 - acc: 0.8132 - val_loss: 0.5204 - val_acc: 0.8437\n",
            "Epoch 555/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5512 - acc: 0.8102 - val_loss: 0.5499 - val_acc: 0.8044\n",
            "Epoch 556/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5491 - acc: 0.8138 - val_loss: 0.5435 - val_acc: 0.8327\n",
            "Epoch 557/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5484 - acc: 0.8134 - val_loss: 0.5595 - val_acc: 0.8110\n",
            "Epoch 558/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5505 - acc: 0.8102 - val_loss: 0.4805 - val_acc: 0.8500\n",
            "Epoch 559/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5514 - acc: 0.8122 - val_loss: 0.5589 - val_acc: 0.8140\n",
            "Epoch 560/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8134 - val_loss: 0.6258 - val_acc: 0.7631\n",
            "Epoch 561/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5496 - acc: 0.8136 - val_loss: 0.6546 - val_acc: 0.7363\n",
            "Epoch 562/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5482 - acc: 0.8140 - val_loss: 0.6189 - val_acc: 0.7813\n",
            "Epoch 563/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8147 - val_loss: 0.5539 - val_acc: 0.8093\n",
            "Epoch 564/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5510 - acc: 0.8123 - val_loss: 0.4706 - val_acc: 0.8606\n",
            "Epoch 565/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5487 - acc: 0.8136 - val_loss: 0.6043 - val_acc: 0.8126\n",
            "Epoch 566/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8153 - val_loss: 0.6893 - val_acc: 0.7144\n",
            "Epoch 567/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8130 - val_loss: 0.4912 - val_acc: 0.8475\n",
            "Epoch 568/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5485 - acc: 0.8123 - val_loss: 0.5270 - val_acc: 0.8245\n",
            "Epoch 569/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5504 - acc: 0.8133 - val_loss: 0.5482 - val_acc: 0.8236\n",
            "Epoch 570/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5501 - acc: 0.8110 - val_loss: 0.5110 - val_acc: 0.8388\n",
            "Epoch 571/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5502 - acc: 0.8154 - val_loss: 0.6054 - val_acc: 0.7706\n",
            "Epoch 572/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5509 - acc: 0.8131 - val_loss: 0.5599 - val_acc: 0.7917\n",
            "Epoch 573/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5492 - acc: 0.8132 - val_loss: 0.5799 - val_acc: 0.7818\n",
            "Epoch 574/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5481 - acc: 0.8151 - val_loss: 0.5386 - val_acc: 0.8417\n",
            "Epoch 575/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5512 - acc: 0.8095 - val_loss: 0.5827 - val_acc: 0.7989\n",
            "Epoch 576/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8115 - val_loss: 0.5885 - val_acc: 0.8065\n",
            "Epoch 577/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8116 - val_loss: 0.5853 - val_acc: 0.8066\n",
            "Epoch 578/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484 - acc: 0.8132 - val_loss: 0.6144 - val_acc: 0.7672\n",
            "Epoch 579/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8136 - val_loss: 0.5034 - val_acc: 0.8327\n",
            "Epoch 580/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5523 - acc: 0.8131 - val_loss: 0.5544 - val_acc: 0.8181\n",
            "Epoch 581/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5491 - acc: 0.8134 - val_loss: 0.5337 - val_acc: 0.8371\n",
            "Epoch 582/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5507 - acc: 0.8134 - val_loss: 0.5925 - val_acc: 0.7855\n",
            "Epoch 583/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8127 - val_loss: 0.5781 - val_acc: 0.8009\n",
            "Epoch 584/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5620 - acc: 0.8014 - val_loss: 0.5268 - val_acc: 0.8319\n",
            "Epoch 585/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5508 - acc: 0.8122 - val_loss: 0.5653 - val_acc: 0.8173\n",
            "Epoch 586/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484 - acc: 0.8154 - val_loss: 0.5948 - val_acc: 0.8107\n",
            "Epoch 587/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5535 - acc: 0.8129 - val_loss: 0.5262 - val_acc: 0.8309\n",
            "Epoch 588/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5508 - acc: 0.8121 - val_loss: 0.5092 - val_acc: 0.8470\n",
            "Epoch 589/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5524 - acc: 0.8101 - val_loss: 0.5628 - val_acc: 0.8251\n",
            "Epoch 590/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5522 - acc: 0.8119 - val_loss: 0.6359 - val_acc: 0.7222\n",
            "Epoch 591/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5482 - acc: 0.8145 - val_loss: 0.5585 - val_acc: 0.8111\n",
            "Epoch 592/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8105 - val_loss: 0.6205 - val_acc: 0.7493\n",
            "Epoch 593/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5494 - acc: 0.8106 - val_loss: 0.5705 - val_acc: 0.8263\n",
            "Epoch 594/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5486 - acc: 0.8120 - val_loss: 0.5288 - val_acc: 0.8348\n",
            "Epoch 595/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8126 - val_loss: 0.5461 - val_acc: 0.8140\n",
            "Epoch 596/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5507 - acc: 0.8127 - val_loss: 0.4979 - val_acc: 0.8491\n",
            "Epoch 597/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5503 - acc: 0.8124 - val_loss: 0.5812 - val_acc: 0.7762\n",
            "Epoch 598/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5489 - acc: 0.8114 - val_loss: 0.5799 - val_acc: 0.8105\n",
            "Epoch 599/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8129 - val_loss: 0.5894 - val_acc: 0.7943\n",
            "Epoch 600/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5504 - acc: 0.8134 - val_loss: 0.5982 - val_acc: 0.7777\n",
            "Epoch 601/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8122 - val_loss: 0.5591 - val_acc: 0.8058\n",
            "Epoch 602/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5494 - acc: 0.8128 - val_loss: 0.5183 - val_acc: 0.8369\n",
            "Epoch 603/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5497 - acc: 0.8128 - val_loss: 0.4903 - val_acc: 0.8493\n",
            "Epoch 604/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5496 - acc: 0.8114 - val_loss: 0.6897 - val_acc: 0.6786\n",
            "Epoch 605/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5506 - acc: 0.8104 - val_loss: 0.5335 - val_acc: 0.8418\n",
            "Epoch 606/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5509 - acc: 0.8102 - val_loss: 0.4944 - val_acc: 0.8401\n",
            "Epoch 607/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5500 - acc: 0.8127 - val_loss: 0.6052 - val_acc: 0.7656\n",
            "Epoch 608/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5476 - acc: 0.8141 - val_loss: 0.5706 - val_acc: 0.8218\n",
            "Epoch 609/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5498 - acc: 0.8131 - val_loss: 0.6469 - val_acc: 0.7421\n",
            "Epoch 610/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5498 - acc: 0.8094 - val_loss: 0.5413 - val_acc: 0.8133\n",
            "Epoch 611/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5488 - acc: 0.8130 - val_loss: 0.5522 - val_acc: 0.8155\n",
            "Epoch 612/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5490 - acc: 0.8131 - val_loss: 0.6543 - val_acc: 0.7390\n",
            "Epoch 613/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5495 - acc: 0.8137 - val_loss: 0.5112 - val_acc: 0.8293\n",
            "Epoch 614/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5492 - acc: 0.8151 - val_loss: 0.6801 - val_acc: 0.6716\n",
            "Epoch 615/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5552 - acc: 0.8101 - val_loss: 0.4996 - val_acc: 0.8515\n",
            "Epoch 616/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484 - acc: 0.8139 - val_loss: 0.5836 - val_acc: 0.7945\n",
            "Epoch 617/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5490 - acc: 0.8134 - val_loss: 0.5162 - val_acc: 0.8538\n",
            "Epoch 618/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5507 - acc: 0.8119 - val_loss: 0.5634 - val_acc: 0.8105\n",
            "Epoch 619/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5502 - acc: 0.8141 - val_loss: 0.5975 - val_acc: 0.8002\n",
            "Epoch 620/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5500 - acc: 0.8143 - val_loss: 0.6237 - val_acc: 0.7643\n",
            "Epoch 621/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5506 - acc: 0.8131 - val_loss: 0.5813 - val_acc: 0.8035\n",
            "Epoch 622/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5513 - acc: 0.8135 - val_loss: 0.5565 - val_acc: 0.8069\n",
            "Epoch 623/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5515 - acc: 0.8130 - val_loss: 0.5300 - val_acc: 0.8355\n",
            "Epoch 624/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5504 - acc: 0.8138 - val_loss: 0.5222 - val_acc: 0.8341\n",
            "Epoch 625/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5517 - acc: 0.8129 - val_loss: 0.5801 - val_acc: 0.8211\n",
            "Epoch 626/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5521 - acc: 0.8109 - val_loss: 0.5185 - val_acc: 0.8393\n",
            "Epoch 627/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5529 - acc: 0.8144 - val_loss: 0.5085 - val_acc: 0.8414\n",
            "Epoch 628/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8144 - val_loss: 0.5500 - val_acc: 0.8113\n",
            "Epoch 629/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5523 - acc: 0.8143 - val_loss: 0.5059 - val_acc: 0.8513\n",
            "Epoch 630/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5509 - acc: 0.8138 - val_loss: 0.5238 - val_acc: 0.8338\n",
            "Epoch 631/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5482 - acc: 0.8131 - val_loss: 0.5303 - val_acc: 0.8293\n",
            "Epoch 632/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5518 - acc: 0.8113 - val_loss: 0.5739 - val_acc: 0.7933\n",
            "Epoch 633/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5515 - acc: 0.8121 - val_loss: 0.5407 - val_acc: 0.8358\n",
            "Epoch 634/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5491 - acc: 0.8153 - val_loss: 0.5690 - val_acc: 0.8282\n",
            "Epoch 635/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5504 - acc: 0.8135 - val_loss: 0.5677 - val_acc: 0.8055\n",
            "Epoch 636/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5486 - acc: 0.8152 - val_loss: 0.5605 - val_acc: 0.8178\n",
            "Epoch 637/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5494 - acc: 0.8164 - val_loss: 0.6029 - val_acc: 0.7791\n",
            "Epoch 638/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5511 - acc: 0.8137 - val_loss: 0.5565 - val_acc: 0.8277\n",
            "Epoch 639/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5524 - acc: 0.8115 - val_loss: 0.5877 - val_acc: 0.7786\n",
            "Epoch 640/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8151 - val_loss: 0.5087 - val_acc: 0.8489\n",
            "Epoch 641/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5565 - acc: 0.8197 - val_loss: 0.5950 - val_acc: 0.8207\n",
            "Epoch 642/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5485 - acc: 0.8154 - val_loss: 0.5348 - val_acc: 0.8456\n",
            "Epoch 643/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5505 - acc: 0.8131 - val_loss: 0.5385 - val_acc: 0.8287\n",
            "Epoch 644/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8132 - val_loss: 0.5755 - val_acc: 0.8055\n",
            "Epoch 645/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5512 - acc: 0.8150 - val_loss: 0.6012 - val_acc: 0.7928\n",
            "Epoch 646/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5497 - acc: 0.8139 - val_loss: 0.5859 - val_acc: 0.8065\n",
            "Epoch 647/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5503 - acc: 0.8129 - val_loss: 0.5362 - val_acc: 0.8241\n",
            "Epoch 648/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8133 - val_loss: 0.5560 - val_acc: 0.8243\n",
            "Epoch 649/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5524 - acc: 0.8148 - val_loss: 0.5688 - val_acc: 0.7883\n",
            "Epoch 650/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5496 - acc: 0.8143 - val_loss: 0.6448 - val_acc: 0.7430\n",
            "Epoch 651/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5518 - acc: 0.8132 - val_loss: 0.5167 - val_acc: 0.8294\n",
            "Epoch 652/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8121 - val_loss: 0.5549 - val_acc: 0.8145\n",
            "Epoch 653/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5512 - acc: 0.8138 - val_loss: 0.6002 - val_acc: 0.7921\n",
            "Epoch 654/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5493 - acc: 0.8111 - val_loss: 0.5650 - val_acc: 0.8125\n",
            "Epoch 655/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5498 - acc: 0.8126 - val_loss: 0.6763 - val_acc: 0.7053\n",
            "Epoch 656/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8136 - val_loss: 0.5214 - val_acc: 0.8395\n",
            "Epoch 657/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5502 - acc: 0.8142 - val_loss: 0.5661 - val_acc: 0.8056\n",
            "Epoch 658/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5513 - acc: 0.8138 - val_loss: 0.5046 - val_acc: 0.8338\n",
            "Epoch 659/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5512 - acc: 0.8121 - val_loss: 0.6623 - val_acc: 0.7348\n",
            "Epoch 660/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5542 - acc: 0.8122 - val_loss: 0.6638 - val_acc: 0.7323\n",
            "Epoch 661/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5546 - acc: 0.8106 - val_loss: 0.5873 - val_acc: 0.8081\n",
            "Epoch 662/1000\n",
            "240/240 [==============================] - 3s 10ms/step - loss: 0.5489 - acc: 0.8141 - val_loss: 0.5819 - val_acc: 0.7642\n",
            "Epoch 663/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5522 - acc: 0.8122 - val_loss: 0.6318 - val_acc: 0.7393\n",
            "Epoch 664/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8128 - val_loss: 0.5131 - val_acc: 0.8248\n",
            "Epoch 665/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5506 - acc: 0.8127 - val_loss: 0.5203 - val_acc: 0.8371\n",
            "Epoch 666/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5494 - acc: 0.8143 - val_loss: 0.6169 - val_acc: 0.7768\n",
            "Epoch 667/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5479 - acc: 0.8142 - val_loss: 0.6088 - val_acc: 0.7764\n",
            "Epoch 668/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5532 - acc: 0.8137 - val_loss: 0.5033 - val_acc: 0.8619\n",
            "Epoch 669/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5510 - acc: 0.8169 - val_loss: 0.6042 - val_acc: 0.8050\n",
            "Epoch 670/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5480 - acc: 0.8158 - val_loss: 0.6729 - val_acc: 0.7049\n",
            "Epoch 671/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5496 - acc: 0.8128 - val_loss: 0.6194 - val_acc: 0.7301\n",
            "Epoch 672/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5495 - acc: 0.8144 - val_loss: 0.5227 - val_acc: 0.8384\n",
            "Epoch 673/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5495 - acc: 0.8116 - val_loss: 0.5545 - val_acc: 0.8080\n",
            "Epoch 674/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5475 - acc: 0.8139 - val_loss: 0.5951 - val_acc: 0.8082\n",
            "Epoch 675/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5496 - acc: 0.8120 - val_loss: 0.6353 - val_acc: 0.7423\n",
            "Epoch 676/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5490 - acc: 0.8133 - val_loss: 0.5005 - val_acc: 0.8480\n",
            "Epoch 677/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5562 - acc: 0.8090 - val_loss: 0.5572 - val_acc: 0.8309\n",
            "Epoch 678/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5497 - acc: 0.8141 - val_loss: 0.5478 - val_acc: 0.8165\n",
            "Epoch 679/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5487 - acc: 0.8141 - val_loss: 0.5426 - val_acc: 0.8423\n",
            "Epoch 680/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5493 - acc: 0.8138 - val_loss: 0.5597 - val_acc: 0.8228\n",
            "Epoch 681/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8157 - val_loss: 0.5339 - val_acc: 0.8327\n",
            "Epoch 682/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5496 - acc: 0.8134 - val_loss: 0.6715 - val_acc: 0.7464\n",
            "Epoch 683/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8143 - val_loss: 0.5442 - val_acc: 0.8399\n",
            "Epoch 684/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5511 - acc: 0.8132 - val_loss: 0.5767 - val_acc: 0.7776\n",
            "Epoch 685/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5505 - acc: 0.8122 - val_loss: 0.5771 - val_acc: 0.8066\n",
            "Epoch 686/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5482 - acc: 0.8148 - val_loss: 0.5940 - val_acc: 0.8072\n",
            "Epoch 687/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5510 - acc: 0.8107 - val_loss: 0.5374 - val_acc: 0.8357\n",
            "Epoch 688/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8136 - val_loss: 0.5453 - val_acc: 0.8245\n",
            "Epoch 689/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5510 - acc: 0.8127 - val_loss: 0.5647 - val_acc: 0.7969\n",
            "Epoch 690/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5501 - acc: 0.8132 - val_loss: 0.5789 - val_acc: 0.8100\n",
            "Epoch 691/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8142 - val_loss: 0.5828 - val_acc: 0.7978\n",
            "Epoch 692/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8118 - val_loss: 0.5927 - val_acc: 0.7850\n",
            "Epoch 693/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8141 - val_loss: 0.5200 - val_acc: 0.8306\n",
            "Epoch 694/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8142 - val_loss: 0.5370 - val_acc: 0.8347\n",
            "Epoch 695/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5482 - acc: 0.8135 - val_loss: 0.5612 - val_acc: 0.8123\n",
            "Epoch 696/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5515 - acc: 0.8095 - val_loss: 0.5473 - val_acc: 0.8205\n",
            "Epoch 697/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8122 - val_loss: 0.5621 - val_acc: 0.8043\n",
            "Epoch 698/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8118 - val_loss: 0.6119 - val_acc: 0.7637\n",
            "Epoch 699/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5503 - acc: 0.8134 - val_loss: 0.5656 - val_acc: 0.8181\n",
            "Epoch 700/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5519 - acc: 0.8121 - val_loss: 0.5609 - val_acc: 0.8039\n",
            "Epoch 701/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5504 - acc: 0.8134 - val_loss: 0.6146 - val_acc: 0.7506\n",
            "Epoch 702/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5510 - acc: 0.8148 - val_loss: 0.5497 - val_acc: 0.8009\n",
            "Epoch 703/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5510 - acc: 0.8114 - val_loss: 0.5458 - val_acc: 0.8257\n",
            "Epoch 704/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5526 - acc: 0.8107 - val_loss: 0.5089 - val_acc: 0.8435\n",
            "Epoch 705/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5505 - acc: 0.8129 - val_loss: 0.5042 - val_acc: 0.8337\n",
            "Epoch 706/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5477 - acc: 0.8148 - val_loss: 0.5897 - val_acc: 0.7736\n",
            "Epoch 707/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5495 - acc: 0.8139 - val_loss: 0.5565 - val_acc: 0.8185\n",
            "Epoch 708/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5508 - acc: 0.8113 - val_loss: 0.5363 - val_acc: 0.8319\n",
            "Epoch 709/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5494 - acc: 0.8138 - val_loss: 0.5133 - val_acc: 0.8467\n",
            "Epoch 710/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5541 - acc: 0.8117 - val_loss: 0.5618 - val_acc: 0.8128\n",
            "Epoch 711/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5498 - acc: 0.8134 - val_loss: 0.5454 - val_acc: 0.8189\n",
            "Epoch 712/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8127 - val_loss: 0.5527 - val_acc: 0.8265\n",
            "Epoch 713/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5495 - acc: 0.8107 - val_loss: 0.5510 - val_acc: 0.8291\n",
            "Epoch 714/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5531 - acc: 0.8101 - val_loss: 0.5805 - val_acc: 0.7936\n",
            "Epoch 715/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5505 - acc: 0.8122 - val_loss: 0.6042 - val_acc: 0.7785\n",
            "Epoch 716/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5503 - acc: 0.8138 - val_loss: 0.6062 - val_acc: 0.7740\n",
            "Epoch 717/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5513 - acc: 0.8109 - val_loss: 0.6045 - val_acc: 0.7729\n",
            "Epoch 718/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5514 - acc: 0.8105 - val_loss: 0.5498 - val_acc: 0.8072\n",
            "Epoch 719/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5502 - acc: 0.8132 - val_loss: 0.5395 - val_acc: 0.8212\n",
            "Epoch 720/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5488 - acc: 0.8136 - val_loss: 0.5725 - val_acc: 0.8032\n",
            "Epoch 721/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5505 - acc: 0.8156 - val_loss: 0.5643 - val_acc: 0.8093\n",
            "Epoch 722/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5480 - acc: 0.8125 - val_loss: 0.5093 - val_acc: 0.8537\n",
            "Epoch 723/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5519 - acc: 0.8112 - val_loss: 0.5633 - val_acc: 0.8182\n",
            "Epoch 724/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5498 - acc: 0.8136 - val_loss: 0.6295 - val_acc: 0.7569\n",
            "Epoch 725/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5522 - acc: 0.8112 - val_loss: 0.5515 - val_acc: 0.8040\n",
            "Epoch 726/1000\n",
            "240/240 [==============================] - 3s 10ms/step - loss: 0.5522 - acc: 0.8110 - val_loss: 0.5566 - val_acc: 0.8288\n",
            "Epoch 727/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5492 - acc: 0.8131 - val_loss: 0.5213 - val_acc: 0.8254\n",
            "Epoch 728/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8130 - val_loss: 0.6256 - val_acc: 0.7573\n",
            "Epoch 729/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8134 - val_loss: 0.5502 - val_acc: 0.8087\n",
            "Epoch 730/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8106 - val_loss: 0.5965 - val_acc: 0.7919\n",
            "Epoch 731/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5514 - acc: 0.8097 - val_loss: 0.4993 - val_acc: 0.8581\n",
            "Epoch 732/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8085 - val_loss: 0.5878 - val_acc: 0.8045\n",
            "Epoch 733/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5506 - acc: 0.8121 - val_loss: 0.5462 - val_acc: 0.8313\n",
            "Epoch 734/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5508 - acc: 0.8118 - val_loss: 0.5394 - val_acc: 0.8238\n",
            "Epoch 735/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5489 - acc: 0.8127 - val_loss: 0.5715 - val_acc: 0.7938\n",
            "Epoch 736/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5505 - acc: 0.8125 - val_loss: 0.6098 - val_acc: 0.7689\n",
            "Epoch 737/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5488 - acc: 0.8137 - val_loss: 0.5362 - val_acc: 0.8368\n",
            "Epoch 738/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5511 - acc: 0.8135 - val_loss: 0.5387 - val_acc: 0.8244\n",
            "Epoch 739/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5500 - acc: 0.8152 - val_loss: 0.5951 - val_acc: 0.7707\n",
            "Epoch 740/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5509 - acc: 0.8093 - val_loss: 0.5355 - val_acc: 0.8263\n",
            "Epoch 741/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5495 - acc: 0.8136 - val_loss: 0.5493 - val_acc: 0.8307\n",
            "Epoch 742/1000\n",
            "240/240 [==============================] - 3s 12ms/step - loss: 0.5508 - acc: 0.8146 - val_loss: 0.6065 - val_acc: 0.8004\n",
            "Epoch 743/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5487 - acc: 0.8147 - val_loss: 0.5687 - val_acc: 0.8082\n",
            "Epoch 744/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8125 - val_loss: 0.5736 - val_acc: 0.8005\n",
            "Epoch 745/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8140 - val_loss: 0.5190 - val_acc: 0.8358\n",
            "Epoch 746/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5490 - acc: 0.8151 - val_loss: 0.5397 - val_acc: 0.8273\n",
            "Epoch 747/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5521 - acc: 0.8134 - val_loss: 0.5552 - val_acc: 0.8140\n",
            "Epoch 748/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8135 - val_loss: 0.6085 - val_acc: 0.7649\n",
            "Epoch 749/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5492 - acc: 0.8137 - val_loss: 0.5428 - val_acc: 0.8254\n",
            "Epoch 750/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5497 - acc: 0.8136 - val_loss: 0.5129 - val_acc: 0.8469\n",
            "Epoch 751/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5489 - acc: 0.8147 - val_loss: 0.5093 - val_acc: 0.8430\n",
            "Epoch 752/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5514 - acc: 0.8118 - val_loss: 0.5030 - val_acc: 0.8334\n",
            "Epoch 753/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5514 - acc: 0.8103 - val_loss: 0.5264 - val_acc: 0.8277\n",
            "Epoch 754/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5501 - acc: 0.8143 - val_loss: 0.6293 - val_acc: 0.7480\n",
            "Epoch 755/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5522 - acc: 0.8110 - val_loss: 0.5529 - val_acc: 0.8162\n",
            "Epoch 756/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5488 - acc: 0.8139 - val_loss: 0.5449 - val_acc: 0.8234\n",
            "Epoch 757/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5495 - acc: 0.8139 - val_loss: 0.5166 - val_acc: 0.8394\n",
            "Epoch 758/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5510 - acc: 0.8158 - val_loss: 0.5466 - val_acc: 0.8293\n",
            "Epoch 759/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8115 - val_loss: 0.5983 - val_acc: 0.7948\n",
            "Epoch 760/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5492 - acc: 0.8133 - val_loss: 0.6225 - val_acc: 0.7901\n",
            "Epoch 761/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5503 - acc: 0.8121 - val_loss: 0.5861 - val_acc: 0.7923\n",
            "Epoch 762/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5491 - acc: 0.8142 - val_loss: 0.5357 - val_acc: 0.8367\n",
            "Epoch 763/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8124 - val_loss: 0.6330 - val_acc: 0.7504\n",
            "Epoch 764/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8115 - val_loss: 0.6329 - val_acc: 0.7681\n",
            "Epoch 765/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5502 - acc: 0.8136 - val_loss: 0.5443 - val_acc: 0.8371\n",
            "Epoch 766/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5545 - acc: 0.8118 - val_loss: 0.5060 - val_acc: 0.8344\n",
            "Epoch 767/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5476 - acc: 0.8126 - val_loss: 0.6039 - val_acc: 0.7777\n",
            "Epoch 768/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5493 - acc: 0.8125 - val_loss: 0.5520 - val_acc: 0.8220\n",
            "Epoch 769/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5513 - acc: 0.8109 - val_loss: 0.5419 - val_acc: 0.8195\n",
            "Epoch 770/1000\n",
            "240/240 [==============================] - 1s 6ms/step - loss: 0.5496 - acc: 0.8146 - val_loss: 0.5422 - val_acc: 0.8186\n",
            "Epoch 771/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8125 - val_loss: 0.5609 - val_acc: 0.8098\n",
            "Epoch 772/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5514 - acc: 0.8123 - val_loss: 0.5818 - val_acc: 0.7905\n",
            "Epoch 773/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5520 - acc: 0.8118 - val_loss: 0.5822 - val_acc: 0.8056\n",
            "Epoch 774/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5501 - acc: 0.8112 - val_loss: 0.5811 - val_acc: 0.7908\n",
            "Epoch 775/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5488 - acc: 0.8145 - val_loss: 0.6065 - val_acc: 0.7744\n",
            "Epoch 776/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8119 - val_loss: 0.5526 - val_acc: 0.8235\n",
            "Epoch 777/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8121 - val_loss: 0.5612 - val_acc: 0.8047\n",
            "Epoch 778/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8148 - val_loss: 0.5554 - val_acc: 0.8116\n",
            "Epoch 779/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8147 - val_loss: 0.4937 - val_acc: 0.8457\n",
            "Epoch 780/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8117 - val_loss: 0.4622 - val_acc: 0.8539\n",
            "Epoch 781/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8107 - val_loss: 0.4994 - val_acc: 0.8467\n",
            "Epoch 782/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5531 - acc: 0.8127 - val_loss: 0.5682 - val_acc: 0.8033\n",
            "Epoch 783/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5496 - acc: 0.8151 - val_loss: 0.4996 - val_acc: 0.8459\n",
            "Epoch 784/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5505 - acc: 0.8088 - val_loss: 0.5669 - val_acc: 0.7987\n",
            "Epoch 785/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5512 - acc: 0.8102 - val_loss: 0.5175 - val_acc: 0.8195\n",
            "Epoch 786/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5511 - acc: 0.8125 - val_loss: 0.5235 - val_acc: 0.8346\n",
            "Epoch 787/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5516 - acc: 0.8136 - val_loss: 0.5415 - val_acc: 0.8280\n",
            "Epoch 788/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5490 - acc: 0.8139 - val_loss: 0.5604 - val_acc: 0.8274\n",
            "Epoch 789/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5517 - acc: 0.8112 - val_loss: 0.5903 - val_acc: 0.7970\n",
            "Epoch 790/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5495 - acc: 0.8139 - val_loss: 0.5210 - val_acc: 0.8316\n",
            "Epoch 791/1000\n",
            "240/240 [==============================] - 3s 10ms/step - loss: 0.5486 - acc: 0.8138 - val_loss: 0.5803 - val_acc: 0.7886\n",
            "Epoch 792/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5495 - acc: 0.8122 - val_loss: 0.6774 - val_acc: 0.6900\n",
            "Epoch 793/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5521 - acc: 0.8122 - val_loss: 0.5726 - val_acc: 0.8119\n",
            "Epoch 794/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484 - acc: 0.8143 - val_loss: 0.5689 - val_acc: 0.8110\n",
            "Epoch 795/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8125 - val_loss: 0.5497 - val_acc: 0.8197\n",
            "Epoch 796/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8136 - val_loss: 0.5681 - val_acc: 0.8060\n",
            "Epoch 797/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8136 - val_loss: 0.6256 - val_acc: 0.7793\n",
            "Epoch 798/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5515 - acc: 0.8097 - val_loss: 0.6069 - val_acc: 0.8061\n",
            "Epoch 799/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5502 - acc: 0.8138 - val_loss: 0.5284 - val_acc: 0.8367\n",
            "Epoch 800/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8138 - val_loss: 0.5257 - val_acc: 0.8375\n",
            "Epoch 801/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5487 - acc: 0.8151 - val_loss: 0.6381 - val_acc: 0.7394\n",
            "Epoch 802/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5499 - acc: 0.8120 - val_loss: 0.5584 - val_acc: 0.7975\n",
            "Epoch 803/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5517 - acc: 0.8129 - val_loss: 0.5728 - val_acc: 0.8245\n",
            "Epoch 804/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5508 - acc: 0.8126 - val_loss: 0.5169 - val_acc: 0.8395\n",
            "Epoch 805/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5538 - acc: 0.8109 - val_loss: 0.6174 - val_acc: 0.7821\n",
            "Epoch 806/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5519 - acc: 0.8114 - val_loss: 0.5868 - val_acc: 0.7819\n",
            "Epoch 807/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5491 - acc: 0.8129 - val_loss: 0.6403 - val_acc: 0.7347\n",
            "Epoch 808/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5515 - acc: 0.8111 - val_loss: 0.5898 - val_acc: 0.7942\n",
            "Epoch 809/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8131 - val_loss: 0.5605 - val_acc: 0.8221\n",
            "Epoch 810/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5513 - acc: 0.8118 - val_loss: 0.6160 - val_acc: 0.7760\n",
            "Epoch 811/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5483 - acc: 0.8135 - val_loss: 0.5129 - val_acc: 0.8453\n",
            "Epoch 812/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8126 - val_loss: 0.5590 - val_acc: 0.7861\n",
            "Epoch 813/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484 - acc: 0.8140 - val_loss: 0.5764 - val_acc: 0.7987\n",
            "Epoch 814/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5519 - acc: 0.8125 - val_loss: 0.5359 - val_acc: 0.8256\n",
            "Epoch 815/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5485 - acc: 0.8134 - val_loss: 0.5544 - val_acc: 0.8210\n",
            "Epoch 816/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5498 - acc: 0.8127 - val_loss: 0.6072 - val_acc: 0.7610\n",
            "Epoch 817/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5507 - acc: 0.8130 - val_loss: 0.5322 - val_acc: 0.8329\n",
            "Epoch 818/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5480 - acc: 0.8134 - val_loss: 0.6582 - val_acc: 0.7213\n",
            "Epoch 819/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5507 - acc: 0.8120 - val_loss: 0.5414 - val_acc: 0.8403\n",
            "Epoch 820/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8138 - val_loss: 0.5530 - val_acc: 0.8424\n",
            "Epoch 821/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8116 - val_loss: 0.5275 - val_acc: 0.8311\n",
            "Epoch 822/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5499 - acc: 0.8149 - val_loss: 0.5254 - val_acc: 0.8480\n",
            "Epoch 823/1000\n",
            "240/240 [==============================] - 3s 12ms/step - loss: 0.5517 - acc: 0.8130 - val_loss: 0.5966 - val_acc: 0.7970\n",
            "Epoch 824/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5505 - acc: 0.8124 - val_loss: 0.5389 - val_acc: 0.8294\n",
            "Epoch 825/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5493 - acc: 0.8109 - val_loss: 0.5567 - val_acc: 0.8308\n",
            "Epoch 826/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5523 - acc: 0.8079 - val_loss: 0.5040 - val_acc: 0.8514\n",
            "Epoch 827/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5477 - acc: 0.8120 - val_loss: 0.5144 - val_acc: 0.8358\n",
            "Epoch 828/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5504 - acc: 0.8103 - val_loss: 0.5351 - val_acc: 0.8212\n",
            "Epoch 829/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5571 - acc: 0.8063 - val_loss: 0.5588 - val_acc: 0.8137\n",
            "Epoch 830/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8131 - val_loss: 0.5684 - val_acc: 0.8067\n",
            "Epoch 831/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5488 - acc: 0.8141 - val_loss: 0.5403 - val_acc: 0.8315\n",
            "Epoch 832/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5510 - acc: 0.8116 - val_loss: 0.5357 - val_acc: 0.8443\n",
            "Epoch 833/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5529 - acc: 0.8127 - val_loss: 0.5319 - val_acc: 0.8250\n",
            "Epoch 834/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8114 - val_loss: 0.5605 - val_acc: 0.8096\n",
            "Epoch 835/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5631 - acc: 0.7996 - val_loss: 0.5522 - val_acc: 0.8193\n",
            "Epoch 836/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5550 - acc: 0.8087 - val_loss: 0.6026 - val_acc: 0.7788\n",
            "Epoch 837/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5558 - acc: 0.8125 - val_loss: 0.5157 - val_acc: 0.8362\n",
            "Epoch 838/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5516 - acc: 0.8126 - val_loss: 0.5203 - val_acc: 0.8415\n",
            "Epoch 839/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8153 - val_loss: 0.5622 - val_acc: 0.7901\n",
            "Epoch 840/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5482 - acc: 0.8123 - val_loss: 0.5583 - val_acc: 0.8123\n",
            "Epoch 841/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5506 - acc: 0.8128 - val_loss: 0.6363 - val_acc: 0.7629\n",
            "Epoch 842/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5496 - acc: 0.8132 - val_loss: 0.5518 - val_acc: 0.8047\n",
            "Epoch 843/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5497 - acc: 0.8131 - val_loss: 0.5544 - val_acc: 0.8372\n",
            "Epoch 844/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8153 - val_loss: 0.5412 - val_acc: 0.8217\n",
            "Epoch 845/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5507 - acc: 0.8102 - val_loss: 0.5474 - val_acc: 0.8089\n",
            "Epoch 846/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5522 - acc: 0.8114 - val_loss: 0.5600 - val_acc: 0.8091\n",
            "Epoch 847/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8105 - val_loss: 0.4927 - val_acc: 0.8483\n",
            "Epoch 848/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5485 - acc: 0.8169 - val_loss: 0.5611 - val_acc: 0.8170\n",
            "Epoch 849/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5485 - acc: 0.8155 - val_loss: 0.5359 - val_acc: 0.8332\n",
            "Epoch 850/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5496 - acc: 0.8149 - val_loss: 0.5408 - val_acc: 0.8181\n",
            "Epoch 851/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5509 - acc: 0.8125 - val_loss: 0.5096 - val_acc: 0.8444\n",
            "Epoch 852/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5499 - acc: 0.8141 - val_loss: 0.5898 - val_acc: 0.7970\n",
            "Epoch 853/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8132 - val_loss: 0.4921 - val_acc: 0.8524\n",
            "Epoch 854/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8118 - val_loss: 0.5074 - val_acc: 0.8406\n",
            "Epoch 855/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5500 - acc: 0.8134 - val_loss: 0.6029 - val_acc: 0.7690\n",
            "Epoch 856/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5488 - acc: 0.8135 - val_loss: 0.6145 - val_acc: 0.7752\n",
            "Epoch 857/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5525 - acc: 0.8102 - val_loss: 0.5838 - val_acc: 0.8082\n",
            "Epoch 858/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5491 - acc: 0.8132 - val_loss: 0.4982 - val_acc: 0.8477\n",
            "Epoch 859/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5518 - acc: 0.8128 - val_loss: 0.4977 - val_acc: 0.8405\n",
            "Epoch 860/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8124 - val_loss: 0.5619 - val_acc: 0.8116\n",
            "Epoch 861/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5503 - acc: 0.8116 - val_loss: 0.5335 - val_acc: 0.8170\n",
            "Epoch 862/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5486 - acc: 0.8130 - val_loss: 0.5810 - val_acc: 0.8131\n",
            "Epoch 863/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5511 - acc: 0.8103 - val_loss: 0.5886 - val_acc: 0.7659\n",
            "Epoch 864/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5501 - acc: 0.8116 - val_loss: 0.5786 - val_acc: 0.7980\n",
            "Epoch 865/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5491 - acc: 0.8108 - val_loss: 0.5616 - val_acc: 0.7952\n",
            "Epoch 866/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8129 - val_loss: 0.6007 - val_acc: 0.7916\n",
            "Epoch 867/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8129 - val_loss: 0.5984 - val_acc: 0.7903\n",
            "Epoch 868/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5489 - acc: 0.8122 - val_loss: 0.5765 - val_acc: 0.8073\n",
            "Epoch 869/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5499 - acc: 0.8114 - val_loss: 0.5749 - val_acc: 0.7867\n",
            "Epoch 870/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5493 - acc: 0.8155 - val_loss: 0.5613 - val_acc: 0.8066\n",
            "Epoch 871/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8120 - val_loss: 0.5466 - val_acc: 0.8277\n",
            "Epoch 872/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5479 - acc: 0.8133 - val_loss: 0.5910 - val_acc: 0.7825\n",
            "Epoch 873/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5504 - acc: 0.8119 - val_loss: 0.5499 - val_acc: 0.8220\n",
            "Epoch 874/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5484 - acc: 0.8123 - val_loss: 0.6098 - val_acc: 0.7661\n",
            "Epoch 875/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5507 - acc: 0.8102 - val_loss: 0.5176 - val_acc: 0.8367\n",
            "Epoch 876/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5502 - acc: 0.8126 - val_loss: 0.5723 - val_acc: 0.7893\n",
            "Epoch 877/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8114 - val_loss: 0.5720 - val_acc: 0.8116\n",
            "Epoch 878/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5488 - acc: 0.8119 - val_loss: 0.6280 - val_acc: 0.7699\n",
            "Epoch 879/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5503 - acc: 0.8110 - val_loss: 0.5174 - val_acc: 0.8276\n",
            "Epoch 880/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5498 - acc: 0.8127 - val_loss: 0.6293 - val_acc: 0.7566\n",
            "Epoch 881/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5515 - acc: 0.8104 - val_loss: 0.6742 - val_acc: 0.7114\n",
            "Epoch 882/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5493 - acc: 0.8128 - val_loss: 0.5067 - val_acc: 0.8474\n",
            "Epoch 883/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5476 - acc: 0.8123 - val_loss: 0.4839 - val_acc: 0.8320\n",
            "Epoch 884/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5483 - acc: 0.8107 - val_loss: 0.5729 - val_acc: 0.7965\n",
            "Epoch 885/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5489 - acc: 0.8120 - val_loss: 0.5874 - val_acc: 0.7789\n",
            "Epoch 886/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8099 - val_loss: 0.5320 - val_acc: 0.8399\n",
            "Epoch 887/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5537 - acc: 0.8095 - val_loss: 0.4900 - val_acc: 0.8558\n",
            "Epoch 888/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8118 - val_loss: 0.6001 - val_acc: 0.7791\n",
            "Epoch 889/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5500 - acc: 0.8133 - val_loss: 0.6345 - val_acc: 0.7334\n",
            "Epoch 890/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5512 - acc: 0.8110 - val_loss: 0.5403 - val_acc: 0.8216\n",
            "Epoch 891/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5516 - acc: 0.8096 - val_loss: 0.5640 - val_acc: 0.7829\n",
            "Epoch 892/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8129 - val_loss: 0.5981 - val_acc: 0.7801\n",
            "Epoch 893/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5481 - acc: 0.8143 - val_loss: 0.5532 - val_acc: 0.8362\n",
            "Epoch 894/1000\n",
            "240/240 [==============================] - 2s 6ms/step - loss: 0.5501 - acc: 0.8111 - val_loss: 0.5728 - val_acc: 0.8091\n",
            "Epoch 895/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8144 - val_loss: 0.6678 - val_acc: 0.7098\n",
            "Epoch 896/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5477 - acc: 0.8142 - val_loss: 0.6052 - val_acc: 0.7752\n",
            "Epoch 897/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5513 - acc: 0.8120 - val_loss: 0.5888 - val_acc: 0.7941\n",
            "Epoch 898/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5503 - acc: 0.8140 - val_loss: 0.5123 - val_acc: 0.8500\n",
            "Epoch 899/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5478 - acc: 0.8120 - val_loss: 0.5416 - val_acc: 0.8176\n",
            "Epoch 900/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8138 - val_loss: 0.5340 - val_acc: 0.8295\n",
            "Epoch 901/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5515 - acc: 0.8105 - val_loss: 0.5132 - val_acc: 0.8430\n",
            "Epoch 902/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5480 - acc: 0.8147 - val_loss: 0.5911 - val_acc: 0.7837\n",
            "Epoch 903/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5494 - acc: 0.8130 - val_loss: 0.5266 - val_acc: 0.8371\n",
            "Epoch 904/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5529 - acc: 0.8120 - val_loss: 0.6003 - val_acc: 0.7698\n",
            "Epoch 905/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5510 - acc: 0.8130 - val_loss: 0.5652 - val_acc: 0.8212\n",
            "Epoch 906/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5494 - acc: 0.8133 - val_loss: 0.5551 - val_acc: 0.8249\n",
            "Epoch 907/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5494 - acc: 0.8127 - val_loss: 0.5137 - val_acc: 0.8363\n",
            "Epoch 908/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5480 - acc: 0.8141 - val_loss: 0.5237 - val_acc: 0.8343\n",
            "Epoch 909/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5518 - acc: 0.8106 - val_loss: 0.5539 - val_acc: 0.8363\n",
            "Epoch 910/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8142 - val_loss: 0.5811 - val_acc: 0.7962\n",
            "Epoch 911/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8132 - val_loss: 0.5214 - val_acc: 0.8434\n",
            "Epoch 912/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5603 - acc: 0.8026 - val_loss: 0.5493 - val_acc: 0.8259\n",
            "Epoch 913/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5504 - acc: 0.8114 - val_loss: 0.5877 - val_acc: 0.7988\n",
            "Epoch 914/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5486 - acc: 0.8151 - val_loss: 0.6202 - val_acc: 0.7824\n",
            "Epoch 915/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5495 - acc: 0.8105 - val_loss: 0.5232 - val_acc: 0.8208\n",
            "Epoch 916/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8125 - val_loss: 0.6027 - val_acc: 0.7664\n",
            "Epoch 917/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8120 - val_loss: 0.5003 - val_acc: 0.8396\n",
            "Epoch 918/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5491 - acc: 0.8112 - val_loss: 0.5721 - val_acc: 0.7996\n",
            "Epoch 919/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5524 - acc: 0.8093 - val_loss: 0.5514 - val_acc: 0.8247\n",
            "Epoch 920/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5516 - acc: 0.8128 - val_loss: 0.5777 - val_acc: 0.8125\n",
            "Epoch 921/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5500 - acc: 0.8123 - val_loss: 0.5368 - val_acc: 0.8386\n",
            "Epoch 922/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5513 - acc: 0.8103 - val_loss: 0.5246 - val_acc: 0.8304\n",
            "Epoch 923/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5510 - acc: 0.8121 - val_loss: 0.5258 - val_acc: 0.8417\n",
            "Epoch 924/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5516 - acc: 0.8120 - val_loss: 0.5261 - val_acc: 0.8288\n",
            "Epoch 925/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5499 - acc: 0.8123 - val_loss: 0.5474 - val_acc: 0.8094\n",
            "Epoch 926/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8136 - val_loss: 0.5857 - val_acc: 0.7905\n",
            "Epoch 927/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5487 - acc: 0.8147 - val_loss: 0.5416 - val_acc: 0.8368\n",
            "Epoch 928/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5485 - acc: 0.8124 - val_loss: 0.5659 - val_acc: 0.8153\n",
            "Epoch 929/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5498 - acc: 0.8146 - val_loss: 0.5509 - val_acc: 0.8238\n",
            "Epoch 930/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5507 - acc: 0.8117 - val_loss: 0.5080 - val_acc: 0.8455\n",
            "Epoch 931/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8122 - val_loss: 0.5885 - val_acc: 0.7801\n",
            "Epoch 932/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5514 - acc: 0.8086 - val_loss: 0.5487 - val_acc: 0.8107\n",
            "Epoch 933/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5495 - acc: 0.8141 - val_loss: 0.5617 - val_acc: 0.8236\n",
            "Epoch 934/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5503 - acc: 0.8120 - val_loss: 0.5235 - val_acc: 0.8409\n",
            "Epoch 935/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8134 - val_loss: 0.5573 - val_acc: 0.8133\n",
            "Epoch 936/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5481 - acc: 0.8142 - val_loss: 0.5943 - val_acc: 0.8166\n",
            "Epoch 937/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5490 - acc: 0.8132 - val_loss: 0.5411 - val_acc: 0.8496\n",
            "Epoch 938/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5522 - acc: 0.8119 - val_loss: 0.6775 - val_acc: 0.6909\n",
            "Epoch 939/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5521 - acc: 0.8129 - val_loss: 0.6196 - val_acc: 0.7505\n",
            "Epoch 940/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5492 - acc: 0.8129 - val_loss: 0.5537 - val_acc: 0.8065\n",
            "Epoch 941/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5505 - acc: 0.8125 - val_loss: 0.5493 - val_acc: 0.8128\n",
            "Epoch 942/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5486 - acc: 0.8138 - val_loss: 0.4952 - val_acc: 0.8438\n",
            "Epoch 943/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5517 - acc: 0.8155 - val_loss: 0.5447 - val_acc: 0.8198\n",
            "Epoch 944/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5509 - acc: 0.8132 - val_loss: 0.5623 - val_acc: 0.8121\n",
            "Epoch 945/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5517 - acc: 0.8141 - val_loss: 0.6327 - val_acc: 0.7776\n",
            "Epoch 946/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5496 - acc: 0.8148 - val_loss: 0.5859 - val_acc: 0.8037\n",
            "Epoch 947/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5495 - acc: 0.8120 - val_loss: 0.5917 - val_acc: 0.7993\n",
            "Epoch 948/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8121 - val_loss: 0.5359 - val_acc: 0.8331\n",
            "Epoch 949/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5492 - acc: 0.8137 - val_loss: 0.5476 - val_acc: 0.8367\n",
            "Epoch 950/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5505 - acc: 0.8140 - val_loss: 0.5899 - val_acc: 0.7877\n",
            "Epoch 951/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8150 - val_loss: 0.4959 - val_acc: 0.8445\n",
            "Epoch 952/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5481 - acc: 0.8117 - val_loss: 0.5657 - val_acc: 0.7981\n",
            "Epoch 953/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5489 - acc: 0.8142 - val_loss: 0.5635 - val_acc: 0.8186\n",
            "Epoch 954/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5540 - acc: 0.8079 - val_loss: 0.5640 - val_acc: 0.8088\n",
            "Epoch 955/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5494 - acc: 0.8110 - val_loss: 0.5616 - val_acc: 0.8095\n",
            "Epoch 956/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8142 - val_loss: 0.5807 - val_acc: 0.7831\n",
            "Epoch 957/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8114 - val_loss: 0.5527 - val_acc: 0.8327\n",
            "Epoch 958/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5484 - acc: 0.8140 - val_loss: 0.5544 - val_acc: 0.8295\n",
            "Epoch 959/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5494 - acc: 0.8128 - val_loss: 0.5305 - val_acc: 0.8188\n",
            "Epoch 960/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5511 - acc: 0.8109 - val_loss: 0.5050 - val_acc: 0.8382\n",
            "Epoch 961/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5486 - acc: 0.8139 - val_loss: 0.5574 - val_acc: 0.8313\n",
            "Epoch 962/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5520 - acc: 0.8106 - val_loss: 0.5413 - val_acc: 0.8362\n",
            "Epoch 963/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5512 - acc: 0.8131 - val_loss: 0.5208 - val_acc: 0.8353\n",
            "Epoch 964/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5506 - acc: 0.8132 - val_loss: 0.5267 - val_acc: 0.8114\n",
            "Epoch 965/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8122 - val_loss: 0.5599 - val_acc: 0.8069\n",
            "Epoch 966/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5478 - acc: 0.8150 - val_loss: 0.5406 - val_acc: 0.8340\n",
            "Epoch 967/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5479 - acc: 0.8136 - val_loss: 0.5396 - val_acc: 0.8228\n",
            "Epoch 968/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5503 - acc: 0.8102 - val_loss: 0.4690 - val_acc: 0.8534\n",
            "Epoch 969/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5500 - acc: 0.8139 - val_loss: 0.6273 - val_acc: 0.7879\n",
            "Epoch 970/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5512 - acc: 0.8117 - val_loss: 0.5566 - val_acc: 0.8216\n",
            "Epoch 971/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5620 - acc: 0.8010 - val_loss: 0.5466 - val_acc: 0.8136\n",
            "Epoch 972/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5568 - acc: 0.8053 - val_loss: 0.5311 - val_acc: 0.8351\n",
            "Epoch 973/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8125 - val_loss: 0.5740 - val_acc: 0.8045\n",
            "Epoch 974/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5503 - acc: 0.8143 - val_loss: 0.6024 - val_acc: 0.7773\n",
            "Epoch 975/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5482 - acc: 0.8140 - val_loss: 0.5264 - val_acc: 0.8256\n",
            "Epoch 976/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5496 - acc: 0.8114 - val_loss: 0.5570 - val_acc: 0.8122\n",
            "Epoch 977/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5502 - acc: 0.8128 - val_loss: 0.4703 - val_acc: 0.8542\n",
            "Epoch 978/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5502 - acc: 0.8142 - val_loss: 0.5323 - val_acc: 0.8251\n",
            "Epoch 979/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5497 - acc: 0.8118 - val_loss: 0.5468 - val_acc: 0.8265\n",
            "Epoch 980/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5468 - acc: 0.8137 - val_loss: 0.5514 - val_acc: 0.8159\n",
            "Epoch 981/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5489 - acc: 0.8141 - val_loss: 0.6128 - val_acc: 0.7857\n",
            "Epoch 982/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5489 - acc: 0.8139 - val_loss: 0.5755 - val_acc: 0.8135\n",
            "Epoch 983/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8142 - val_loss: 0.5974 - val_acc: 0.7941\n",
            "Epoch 984/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5494 - acc: 0.8132 - val_loss: 0.5706 - val_acc: 0.8040\n",
            "Epoch 985/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5487 - acc: 0.8129 - val_loss: 0.5152 - val_acc: 0.8318\n",
            "Epoch 986/1000\n",
            "240/240 [==============================] - 2s 9ms/step - loss: 0.5510 - acc: 0.8131 - val_loss: 0.5072 - val_acc: 0.8283\n",
            "Epoch 987/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8134 - val_loss: 0.5312 - val_acc: 0.8526\n",
            "Epoch 988/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5500 - acc: 0.8123 - val_loss: 0.5847 - val_acc: 0.7947\n",
            "Epoch 989/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5482 - acc: 0.8127 - val_loss: 0.5527 - val_acc: 0.8111\n",
            "Epoch 990/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5501 - acc: 0.8128 - val_loss: 0.5654 - val_acc: 0.8238\n",
            "Epoch 991/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5498 - acc: 0.8124 - val_loss: 0.5329 - val_acc: 0.8408\n",
            "Epoch 992/1000\n",
            "240/240 [==============================] - 2s 10ms/step - loss: 0.5502 - acc: 0.8130 - val_loss: 0.5665 - val_acc: 0.8073\n",
            "Epoch 993/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5494 - acc: 0.8146 - val_loss: 0.6194 - val_acc: 0.7539\n",
            "Epoch 994/1000\n",
            "240/240 [==============================] - 2s 8ms/step - loss: 0.5508 - acc: 0.8104 - val_loss: 0.5708 - val_acc: 0.7898\n",
            "Epoch 995/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5509 - acc: 0.8140 - val_loss: 0.5571 - val_acc: 0.8016\n",
            "Epoch 996/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5583 - acc: 0.8143 - val_loss: 0.5916 - val_acc: 0.8101\n",
            "Epoch 997/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5544 - acc: 0.8127 - val_loss: 0.5633 - val_acc: 0.8202\n",
            "Epoch 998/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5493 - acc: 0.8142 - val_loss: 0.6683 - val_acc: 0.7291\n",
            "Epoch 999/1000\n",
            "240/240 [==============================] - 2s 7ms/step - loss: 0.5504 - acc: 0.8138 - val_loss: 0.5970 - val_acc: 0.7846\n",
            "Epoch 1000/1000\n",
            "240/240 [==============================] - 3s 11ms/step - loss: 0.5495 - acc: 0.8133 - val_loss: 0.6177 - val_acc: 0.7727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb22c1aec50>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functional API"
      ],
      "metadata": {
        "id": "nnaMCCt_2-Wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "m3DXXa4s026W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = Input(shape =(50,),name = 'input')\n",
        "h1 = Dense(30,activation = 'relu',kernel_regularizer = L2(0.01),name ='h1')(x)\n",
        "bn1 = BatchNormalization(name = 'bn_h1')(h1)\n",
        "dr1 = Dropout(0.2,name = 'dr_h1')(bn1)\n",
        "\n",
        "h2 = Dense(20,activation = 'relu',kernel_regularizer = L2(0.01),name ='h2')(dr1)\n",
        "bn2 = BatchNormalization(name = 'bn_h2')(h2)\n",
        "dr2 = Dropout(0.2,name = 'dr_h2')(bn2)\n",
        "\n",
        "h3 = Dense(10,activation = 'relu',kernel_regularizer = L2(0.01),name ='h3')(dr2)\n",
        "bn3 = BatchNormalization(name = 'bn_h3')(h3)\n",
        "dr3 = Dropout(0.2,name = 'dr_h3')(bn3)\n",
        "\n",
        "output = Dense(1,activation = 'sigmoid',name = 'output')(dr3)"
      ],
      "metadata": {
        "id": "wkewEAPRS3rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fn = Model(inputs = x,outputs = output)"
      ],
      "metadata": {
        "id": "quleIqgaT1xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot_model(model = model_fn,show_shapes= True)"
      ],
      "metadata": {
        "id": "oChEC3HKV3kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYGizRIWV9n9",
        "outputId": "6cb1614f-9056-4648-f8f8-09de2164900a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 50)]              0         \n",
            "                                                                 \n",
            " h1 (Dense)                  (None, 30)                1530      \n",
            "                                                                 \n",
            " bn_h1 (BatchNormalization)  (None, 30)                120       \n",
            "                                                                 \n",
            " dr_h1 (Dropout)             (None, 30)                0         \n",
            "                                                                 \n",
            " h2 (Dense)                  (None, 20)                620       \n",
            "                                                                 \n",
            " bn_h2 (BatchNormalization)  (None, 20)                80        \n",
            "                                                                 \n",
            " dr_h2 (Dropout)             (None, 20)                0         \n",
            "                                                                 \n",
            " h3 (Dense)                  (None, 10)                210       \n",
            "                                                                 \n",
            " bn_h3 (BatchNormalization)  (None, 10)                40        \n",
            "                                                                 \n",
            " dr_h3 (Dropout)             (None, 10)                0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2611 (10.20 KB)\n",
            "Trainable params: 2491 (9.73 KB)\n",
            "Non-trainable params: 120 (480.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keras Utility Functions : Callbacks"
      ],
      "metadata": {
        "id": "_92P8JWHZ5CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# callback to get information in the time of training what is happening while learing like flag etc.\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping,Callback\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "d5FMVOKcZVbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "earlystop = EarlyStopping(monitor = 'loss',patience = 5)"
      ],
      "metadata": {
        "id": "KCZNtN0xZ3Bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputFolder = './Sub_model_output'\n",
        "if not os.path.exists(outputFolder):\n",
        "  os.makedirs(outputFolder)"
      ],
      "metadata": {
        "id": "QD10k4HKZ2-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = outputFolder + '/weights-{epoch:02d}-{loss:.4f}.h5'\n",
        "checkpoint = ModelCheckpoint(filepath = filepath,save_weights_only = True,monitor = 'val_loss',mode = 'min',save_best_only = False,save_freq = 50)"
      ],
      "metadata": {
        "id": "bAVekSo2Z21x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_custom_callback(Callback):\n",
        "  def __init__(self,features,target):\n",
        "    self.test_data = (features,target)\n",
        "    self.auc = []\n",
        "\n",
        "  def on_epoch_end(self,epoch,logs = None):\n",
        "    y_pred = self.model.predict(self.test_data[0])\n",
        "    auc = roc_auc_score(self.test_data[1],y_pred)\n",
        "    print(' \\n auc score for val set :',auc,'\\n')\n",
        "    self.auc.append((epoch,auc))\n",
        "    return"
      ],
      "metadata": {
        "id": "4xpAwXjtZ2m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mycallback = my_custom_callback(sd_x_test,y_val)"
      ],
      "metadata": {
        "id": "F3QGD30KgNKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fn.compile(optimizer= 'adam',loss = 'binary_crossentropy',metrics =['acc'])"
      ],
      "metadata": {
        "id": "zWW_qiKQWWRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fn.fit(sd_x_train,y_train,validation_data = (sd_x_test,y_val),class_weight = cw_dict,\n",
        "              epochs = 500,batch_size = 1000,verbose = 1,callbacks =[mycallback,earlystop,checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACyqRc0jXKip",
        "outputId": "cb790607-2729-434b-b21e-c52e324d31ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.7110685492488035 \n",
            "\n",
            "240/240 [==============================] - 9s 31ms/step - loss: 1.1028 - acc: 0.5457 - val_loss: 0.8624 - val_acc: 0.5356\n",
            "Epoch 2/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.7997990435112127 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.7003 - acc: 0.6970 - val_loss: 0.5708 - val_acc: 0.8496\n",
            "Epoch 3/500\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8225554465812591 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5741 - acc: 0.7793 - val_loss: 0.4991 - val_acc: 0.8645\n",
            "Epoch 4/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8262587984183755 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5401 - acc: 0.7946 - val_loss: 0.5119 - val_acc: 0.8501\n",
            "Epoch 5/500\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8321262895433205 \n",
            "\n",
            "240/240 [==============================] - 7s 28ms/step - loss: 0.5274 - acc: 0.8020 - val_loss: 0.4681 - val_acc: 0.8586\n",
            "Epoch 6/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8375668694098123 \n",
            "\n",
            "240/240 [==============================] - 5s 22ms/step - loss: 0.5231 - acc: 0.8055 - val_loss: 0.4876 - val_acc: 0.8462\n",
            "Epoch 7/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.829543546423458 \n",
            "\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5225 - acc: 0.8060 - val_loss: 0.5168 - val_acc: 0.8162\n",
            "Epoch 8/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8324684091744967 \n",
            "\n",
            "240/240 [==============================] - 8s 33ms/step - loss: 0.5202 - acc: 0.8067 - val_loss: 0.4765 - val_acc: 0.8482\n",
            "Epoch 9/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8354270525941135 \n",
            "\n",
            "240/240 [==============================] - 6s 24ms/step - loss: 0.5175 - acc: 0.8064 - val_loss: 0.4671 - val_acc: 0.8503\n",
            "Epoch 10/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8357952101067322 \n",
            "\n",
            "240/240 [==============================] - 7s 28ms/step - loss: 0.5167 - acc: 0.8082 - val_loss: 0.5059 - val_acc: 0.8240\n",
            "Epoch 11/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8356461306825073 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5149 - acc: 0.8082 - val_loss: 0.4617 - val_acc: 0.8468\n",
            "Epoch 12/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8412127931334612 \n",
            "\n",
            "240/240 [==============================] - 8s 33ms/step - loss: 0.5162 - acc: 0.8077 - val_loss: 0.4638 - val_acc: 0.8477\n",
            "Epoch 13/500\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8388667159318675 \n",
            "\n",
            "240/240 [==============================] - 7s 27ms/step - loss: 0.5152 - acc: 0.8073 - val_loss: 0.4810 - val_acc: 0.8458\n",
            "Epoch 14/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8389752067789162 \n",
            "\n",
            "240/240 [==============================] - 6s 25ms/step - loss: 0.5154 - acc: 0.8068 - val_loss: 0.5098 - val_acc: 0.8150\n",
            "Epoch 15/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8412089891449289 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5148 - acc: 0.8070 - val_loss: 0.4683 - val_acc: 0.8390\n",
            "Epoch 16/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8389455573552027 \n",
            "\n",
            "240/240 [==============================] - 8s 31ms/step - loss: 0.5138 - acc: 0.8103 - val_loss: 0.5052 - val_acc: 0.8191\n",
            "Epoch 17/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8384929511017926 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5144 - acc: 0.8084 - val_loss: 0.5143 - val_acc: 0.8054\n",
            "Epoch 18/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8392041514015101 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5141 - acc: 0.8084 - val_loss: 0.4568 - val_acc: 0.8533\n",
            "Epoch 19/500\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8399912292567646 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5121 - acc: 0.8082 - val_loss: 0.4406 - val_acc: 0.8558\n",
            "Epoch 20/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8399413544148254 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5141 - acc: 0.8055 - val_loss: 0.4858 - val_acc: 0.8327\n",
            "Epoch 21/500\n",
            "1875/1875 [==============================] - 4s 2ms/step\n",
            " \n",
            " auc score for val set : 0.839605222109205 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5122 - acc: 0.8102 - val_loss: 0.4671 - val_acc: 0.8417\n",
            "Epoch 22/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8405759503568828 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5126 - acc: 0.8078 - val_loss: 0.4578 - val_acc: 0.8378\n",
            "Epoch 23/500\n",
            "1875/1875 [==============================] - 5s 3ms/step\n",
            " \n",
            " auc score for val set : 0.8405926941584858 \n",
            "\n",
            "240/240 [==============================] - 12s 50ms/step - loss: 0.5127 - acc: 0.8083 - val_loss: 0.5017 - val_acc: 0.8186\n",
            "Epoch 24/500\n",
            "1875/1875 [==============================] - 3s 2ms/step\n",
            " \n",
            " auc score for val set : 0.8406275152091355 \n",
            "\n",
            "240/240 [==============================] - 7s 29ms/step - loss: 0.5137 - acc: 0.8070 - val_loss: 0.4935 - val_acc: 0.8224\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f6ad5997670>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mycallback.auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6eQASODhXYj",
        "outputId": "6f09557d-b26c-4093-94b8-8a486d72ab9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0, 0.7110685492488035),\n",
              " (1, 0.7997990435112127),\n",
              " (2, 0.8225554465812591),\n",
              " (3, 0.8262587984183755),\n",
              " (4, 0.8321262895433205),\n",
              " (5, 0.8375668694098123),\n",
              " (6, 0.829543546423458),\n",
              " (7, 0.8324684091744967),\n",
              " (8, 0.8354270525941135),\n",
              " (9, 0.8357952101067322),\n",
              " (10, 0.8356461306825073),\n",
              " (11, 0.8412127931334612),\n",
              " (12, 0.8388667159318675),\n",
              " (13, 0.8389752067789162),\n",
              " (14, 0.8412089891449289),\n",
              " (15, 0.8389455573552027),\n",
              " (16, 0.8384929511017926),\n",
              " (17, 0.8392041514015101),\n",
              " (18, 0.8399912292567646),\n",
              " (19, 0.8399413544148254),\n",
              " (20, 0.839605222109205),\n",
              " (21, 0.8405759503568828),\n",
              " (22, 0.8405926941584858),\n",
              " (23, 0.8406275152091355)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(data = mycallback.auc,columns = ['epochs','val auc']).plot(\n",
        "    x= 'epochs',y = 'val auc')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "nSVYZNzSlxiC",
        "outputId": "0974fa6f-fe5e-4885-f2ff-7d54e072163d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epochs'>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "w0ij8FtZrYwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "# SAVE THE ARCITETURE\n",
        "model_json = model_fn.to_json()"
      ],
      "metadata": {
        "id": "-YjsHCu6mIRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "GzulaHTvrv4n",
        "outputId": "6fde1c76-8b9d-43ad-a40f-100080813f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"class_name\": \"Functional\", \"config\": {\"name\": \"model\", \"trainable\": true, \"layers\": [{\"module\": \"keras.layers\", \"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 50], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"input\"}, \"registered_name\": null, \"name\": \"input\", \"inbound_nodes\": []}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"h1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 30, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}, \"registered_name\": null}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 50]}, \"name\": \"h1\", \"inbound_nodes\": [[[\"input\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"bn_h1\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 30]}, \"name\": \"bn_h1\", \"inbound_nodes\": [[[\"h1\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dr_h1\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.2, \"noise_shape\": null, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 30]}, \"name\": \"dr_h1\", \"inbound_nodes\": [[[\"bn_h1\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"h2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 20, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}, \"registered_name\": null}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 30]}, \"name\": \"h2\", \"inbound_nodes\": [[[\"dr_h1\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"bn_h2\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 20]}, \"name\": \"bn_h2\", \"inbound_nodes\": [[[\"h2\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dr_h2\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.2, \"noise_shape\": null, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 20]}, \"name\": \"dr_h2\", \"inbound_nodes\": [[[\"bn_h2\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"h3\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": {\"module\": \"keras.regularizers\", \"class_name\": \"L2\", \"config\": {\"l2\": 0.009999999776482582}, \"registered_name\": null}, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 20]}, \"name\": \"h3\", \"inbound_nodes\": [[[\"dr_h2\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"BatchNormalization\", \"config\": {\"name\": \"bn_h3\", \"trainable\": true, \"dtype\": \"float32\", \"axis\": [1], \"momentum\": 0.99, \"epsilon\": 0.001, \"center\": true, \"scale\": true, \"beta_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"gamma_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"moving_mean_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"moving_variance_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Ones\", \"config\": {}, \"registered_name\": null}, \"beta_regularizer\": null, \"gamma_regularizer\": null, \"beta_constraint\": null, \"gamma_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 10]}, \"name\": \"bn_h3\", \"inbound_nodes\": [[[\"h3\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"Dropout\", \"config\": {\"name\": \"dr_h3\", \"trainable\": true, \"dtype\": \"float32\", \"rate\": 0.2, \"noise_shape\": null, \"seed\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 10]}, \"name\": \"dr_h3\", \"inbound_nodes\": [[[\"bn_h3\", 0, 0, {}]]]}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"output\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 1, \"activation\": \"sigmoid\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 10]}, \"name\": \"output\", \"inbound_nodes\": [[[\"dr_h3\", 0, 0, {}]]]}], \"input_layers\": [[\"input\", 0, 0]], \"output_layers\": [[\"output\", 0, 0]]}, \"keras_version\": \"2.15.0\", \"backend\": \"tensorflow\"}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#os.makedirs('./model_json_v0_json')"
      ],
      "metadata": {
        "id": "oREdJ6eTtNe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open( 'model_json_v0_json/model_json_v0.json','w') as json_file:\n",
        "  json_file.write(model_json)"
      ],
      "metadata": {
        "id": "ujaa7mH_ryN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open( 'model_json_v0_json/model_json_v0_scaler','wb') as sc:\n",
        "  pickle.dump(scaler,sc)"
      ],
      "metadata": {
        "id": "C3w2e5SStBid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Model"
      ],
      "metadata": {
        "id": "K8BAz4PWv1o_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n"
      ],
      "metadata": {
        "id": "6N4QHS-3vhCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD THE ACHITECTURE\n",
        "json_file = open('./model_json_v0_json/model_json_v0.json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)"
      ],
      "metadata": {
        "id": "LusulRU4wsx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD THE DESIRED WEIGHTS\n",
        "loaded_model.load_weights('/content/Sub_model_output/weights-11-0.5162.h5')"
      ],
      "metadata": {
        "id": "GdxjPdwxxULb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSDfOVexzNtr",
        "outputId": "b234e9aa-7f98-4edb-f3ea-dbb1a99adf73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 50)]              0         \n",
            "                                                                 \n",
            " h1 (Dense)                  (None, 30)                1530      \n",
            "                                                                 \n",
            " bn_h1 (BatchNormalization)  (None, 30)                120       \n",
            "                                                                 \n",
            " dr_h1 (Dropout)             (None, 30)                0         \n",
            "                                                                 \n",
            " h2 (Dense)                  (None, 20)                620       \n",
            "                                                                 \n",
            " bn_h2 (BatchNormalization)  (None, 20)                80        \n",
            "                                                                 \n",
            " dr_h2 (Dropout)             (None, 20)                0         \n",
            "                                                                 \n",
            " h3 (Dense)                  (None, 10)                210       \n",
            "                                                                 \n",
            " bn_h3 (BatchNormalization)  (None, 10)                40        \n",
            "                                                                 \n",
            " dr_h3 (Dropout)             (None, 10)                0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2611 (10.20 KB)\n",
            "Trainable params: 2491 (9.73 KB)\n",
            "Non-trainable params: 120 (480.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = open( 'model_json_v0_json/model_json_v0_scaler','rb')"
      ],
      "metadata": {
        "id": "zW6hDPyMzSPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = pickle.load(sc)"
      ],
      "metadata": {
        "id": "nFIVZhPyzrq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc.close()"
      ],
      "metadata": {
        "id": "0_htpJxwzxv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model.predict(sd_x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fp2eykSBz02I",
        "outputId": "284a1d86-702e-43db-a1fd-29801edca80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33776203],\n",
              "       [0.49281836],\n",
              "       [0.4861902 ],\n",
              "       ...,\n",
              "       [0.9552909 ],\n",
              "       [0.2595592 ],\n",
              "       [0.32383576]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roc_auc_score(y_val,loaded_model.predict(sd_x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxZjvzTX0OD0",
        "outputId": "c54ad3b8-58f7-416c-a6ea-ee3945e1c552"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 5s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8337194368668377"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzwNzkFA0a3i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}